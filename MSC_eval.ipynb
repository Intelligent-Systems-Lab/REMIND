{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "df = pd.read_json(\"msc_self_instruct.jsonl\", lines=True)\n",
    "\n",
    "answer_df = pd.DataFrame()\n",
    "answer_df['dialog'] = None\n",
    "answer_df['question'] = None\n",
    "answer_df['gold_answer'] = None\n",
    "answer_df['long_mem_result'] = None\n",
    "answer_df['long_mem_answer'] = None\n",
    "answer_df['long_mem_f1'] = None\n",
    "answer_df['long_mem_rc'] = None\n",
    "answer_df['long_mem_pre'] = None\n",
    "answer_df['long_mem_recall_result'] = None\n",
    "answer_df['long_mem_recall_answer'] = None\n",
    "answer_df['long_mem_recall_f1'] = None\n",
    "answer_df['long_mem_recall_rc'] = None\n",
    "answer_df['long_mem_recall_pre'] = None\n",
    "\n",
    "for i in range(500):\n",
    "    # Add dialog\n",
    "    current_time = datetime.strptime(\"2024/11/1 12:00\", \"%Y/%m/%d %H:%M\")\n",
    "    dialog_data = []\n",
    "    for dialog_session in df['previous_dialogs'][i]:\n",
    "        session = []\n",
    "        for count in range(int(len(dialog_session['dialog'])/2)):\n",
    "            chat_log = {\"text\":f\"user:{dialog_session['dialog'][2*count]['text']}, assistant:{dialog_session['dialog'][2*count+1]['text']}\", \"time\":current_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")}\n",
    "            session.append(chat_log)\n",
    "            current_time = current_time + timedelta(minutes=1)\n",
    "        dialog_data.append(session)\n",
    "    answer_df.loc[i, 'dialog'] = str(dialog_data)\n",
    "    \n",
    "    # Add question & answer\n",
    "    answer_df.loc[i, 'question'] = f\"{df['self_instruct'][i]['B']}\"\n",
    "    answer_df.loc[i, 'gold_answer'] = f\"{df['self_instruct'][i]['A']}\"\n",
    "answer_df.to_json(\"MSC_datasets.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "answer_df = pd.read_json(\"MSC_datasets.json\", lines=True)\n",
    "# answer_df = pd.read_json(\"MSC_eval.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect existed deafult user group memory space, loading...\n",
      "Detect existed deafult user child memory space, loading...\n"
     ]
    }
   ],
   "source": [
    "from long_memory.component import WeaviateLongMemory\n",
    "long_mem = WeaviateLongMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def llm_create(prompt):\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "            temperature=0\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "\n",
    "classify_instruct=\"\"\"The summary should focus on keywords such as personal preferences, experiences, activities, and locations.\"\"\"\n",
    "\n",
    "recall_instruct=\"\"\"You will get a question about user. find relative memory as more as possible, don't give up easily\"\"\"\n",
    "\n",
    "answer_prompt = \"\"\"Base on the following document and answer the question.\n",
    "If you are User, what will you say, give a brief answer\n",
    "\n",
    "Question:{question}\n",
    "\n",
    "Document:{docs}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===1===\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "\u001b[34mSave chat logs to long memory done.\u001b[0m\n",
      "===4===\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "\u001b[34mSave chat logs to long memory done.\u001b[0m\n",
      "===15===\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "Chat logs not correct, missing id:{3}, unknown id:set(), retry..\n",
      "\u001b[34mSave chat logs to long memory done.\u001b[0m\n",
      "===19===\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "\u001b[34mSave chat logs to long memory done.\u001b[0m\n",
      "===23===\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "\u001b[34mSave chat logs to long memory done.\u001b[0m\n",
      "===33===\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "\u001b[34mSave chat logs to long memory done.\u001b[0m\n",
      "===34===\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "\u001b[34mSave chat logs to long memory done.\u001b[0m\n",
      "===38===\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "\u001b[34mSave chat logs to long memory done.\u001b[0m\n",
      "===39===\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "Chat logs not correct, missing id:{5}, unknown id:set(), retry..\n",
      "Chat logs not correct, missing id:{5}, unknown id:set(), retry..\n",
      "Chat logs not correct, missing id:{4, 5}, unknown id:set(), retry..\n",
      "\u001b[34mSave chat logs to long memory done.\u001b[0m\n",
      "===60===\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "Chat logs not correct, missing id:{0, 9}, unknown id:set(), retry..\n",
      "\u001b[34mSave chat logs to long memory done.\u001b[0m\n",
      "===61===\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "\u001b[34mSave chat logs to long memory done.\u001b[0m\n",
      "===63===\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "\u001b[34mSave chat logs to long memory done.\u001b[0m\n",
      "===68===\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "\u001b[34mSave chat logs to long memory done.\u001b[0m\n",
      "===69===\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "\u001b[34mSave chat logs to long memory done.\u001b[0m\n",
      "===70===\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "\u001b[34mSave chat logs to long memory done.\u001b[0m\n",
      "===75===\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "\u001b[34mSave chat logs to long memory done.\u001b[0m\n",
      "===76===\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "\u001b[34mSave chat logs to long memory done.\u001b[0m\n",
      "===80===\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "\u001b[34mSave chat logs to long memory done.\u001b[0m\n",
      "===82===\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "\u001b[34mSave chat logs to long memory done.\u001b[0m\n",
      "===84===\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "\u001b[34mSave chat logs to long memory done.\u001b[0m\n",
      "===88===\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "\u001b[34mSave chat logs to long memory done.\u001b[0m\n",
      "===90===\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "\u001b[34mSave chat logs to long memory done.\u001b[0m\n",
      "===96===\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "\u001b[34mSave chat logs to long memory done.\u001b[0m\n",
      "===99===\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "\u001b[34mSave chat logs to long memory done.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "error_list = []\n",
    "error_log = []\n",
    "for i in range(1):\n",
    "    print(f'==={i}===')\n",
    "    try:\n",
    "        # generate result\n",
    "        long_mem.del_memory()\n",
    "        dialogs = []\n",
    "        for dialog_session in eval(answer_df.loc[i, 'dialog']):\n",
    "            dialogs.extend(dialog_session)\n",
    "        long_mem.add_chat_logs(dialogs, other_instruct=classify_instruct)\n",
    "        question = f\"{answer_df.loc[i, 'question']}\"\n",
    "        answer_df.loc[i, 'long_mem_result'] = str(long_mem.get_memory(question, recall=False))\n",
    "        answer_df.loc[i, 'long_mem_recall_result'] = str(long_mem.get_memory(question, recall=True, other_instruct=recall_instruct))\n",
    "        \n",
    "        # response\n",
    "        p = answer_prompt.format(question=answer_df.loc[i, 'question'], docs=answer_df.loc[i, 'long_mem_result'])\n",
    "        long_mem_answer = llm_create(p)\n",
    "        answer_df.loc[i, 'long_mem_answer'] = long_mem_answer\n",
    "        \n",
    "        p = answer_prompt.format(question=answer_df.loc[i, 'question'], docs=answer_df.loc[i, 'long_mem_recall_result'])\n",
    "        long_mem_recall_answer = llm_create(p)\n",
    "        answer_df.loc[i, 'long_mem_recall_answer'] = long_mem_recall_answer\n",
    "    except Exception as e:\n",
    "        error_list.append(i)\n",
    "        error_log.append(e)\n",
    "        print(f'----error:{e}----')\n",
    "    if (i+1)%20==0:\n",
    "        answer_df.to_json(\"MSC_eval.json\", orient=\"records\", lines=True)\n",
    "answer_df.to_json(\"MSC_eval.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt 新增兩者可以互相紀錄, 可以不只一組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_mem.get_memory('Hey, remember that time we talked about your concerts? What was that specific color of the hat you mentioned you later on?', recall=True, other_instruct=recall_instruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[82]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Question': 'Hey, remember that time we talked about my grandma Frankie? What did I tell you we usually end up having for dinner on Thanksgiving at her place?',\n",
       " 'records': [{'search_times': 1,\n",
       "   'used_kewords': 'Hey, remember that time we talked about my grandma Frankie? What did I tell you we usually end up having for dinner on Thanksgiving at her place?',\n",
       "   'searched memory': {'text': 'User shares travel experiences in Spain while the assistant expresses a lack of travel. They also discuss feelings regarding family Thanksgiving traditions.',\n",
       "    'time': '2024/11/01 12:04'},\n",
       "   'thought': \"The information about Thanksgiving dinner at your grandma Frankie's house has been retrieved from the related discussions about family traditions.\",\n",
       "   'evdience': [{'text': \"user:I've been to spain a few times, where do you go for thanksgiving?, assistant:My grandma frankie s house. My mom s mom who lives in ojai.\"},\n",
       "    {'text': 'User shares travel experiences in Spain while the assistant expresses a lack of travel. They also discuss feelings regarding family Thanksgiving traditions.'}],\n",
       "   'next_action': 'end'},\n",
       "  {'end': 'sufficient'}]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_mem.recall_search_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'group': 'User shares enjoyment of traveling, mentioning visits to Spain. Assistant reveals they do not travel much, usually staying home except for Thanksgiving.',\n",
       "  'children': [{'text': \"user:That's great, does your family like to travel? I do, assistant:No. Not too much. I take a school bus but we mostly stay at home. Except thanksgiving\",\n",
       "    'time': '2024/11/01 12:03'},\n",
       "   {'text': \"user:I've been to spain a few times, where do you go for thanksgiving?, assistant:My grandma frankie s house. My mom s mom who lives in ojai.\",\n",
       "    'time': '2024/11/01 12:04'},\n",
       "   {'text': \"user:What's it like in Spain?, assistant:I have never been to Spain, i though you \",\n",
       "    'time': '2024/11/01 12:08'}]},\n",
       " {'group': \"User inquires about Thanksgiving traditions. Assistant humorously notes their grandmother's cooking is bad, leading to meals from Pollo Loco.\",\n",
       "  'children': [{'text': 'user:That sounds like fun, with lots of good food, assistant:Not really. She s a bad cook and we end up getting pollo loco a lot',\n",
       "    'time': '2024/11/01 12:05'},\n",
       "   {'text': 'user:Oh no! But you still have to love grandma lol, assistant:I love my grandma frankie. But she has whiskers that hurt my face when she hugs me',\n",
       "    'time': '2024/11/01 12:06'}]},\n",
       " {'group': \"User and assistant discuss personal experiences regarding feeling upset, potential support from family, and a friend's misbehavior. The conversation touches on relationship dynamics and coping mechanisms.\",\n",
       "  'children': [{'text': 'user:That must have been very upsetting for you. Do you have a phone? Some of the newer ones take really good photos, assistant:I have an Obama phone. The camera has tape over it so that I can’t get hacked and trafficked. ',\n",
       "    'time': '2024/11/01 12:20'},\n",
       "   {'text': 'user:Did you tell anyone about what Rico did? Maybe you could tell a teacher and they could help., assistant:Rico is the teacher! I mean, his mom is so she might as well be her name is Patricia',\n",
       "    'time': '2024/11/01 12:21'},\n",
       "   {'text': 'user:How about your brother? Do you get on well with him?, assistant:Yeah. I like him. He doesn’t pinch my stomach or ask me to do algebra. You want to marry him?',\n",
       "    'time': '2024/11/01 12:22'},\n",
       "   {'text': 'user:No, thanks, I am way too old for him. Would he be able to help you deal with Rico?, assistant:Oooh! That’s a good idea. Get my brother to take the abuse instead of me. But I don’t think my brother would take the abuse he would probably abuse Rico instead',\n",
       "    'time': '2024/11/01 12:23'}]},\n",
       " {'group': \"User discusses difficulties with algebra homework, expressing concern for the assistant's understanding. Assistant acknowledges the complexity compared to regular math.\",\n",
       "  'children': [{'text': 'user:Hello, how are you today?, assistant:Tired. Spent all night trying to do algebra homework I don t understand.',\n",
       "    'time': '2024/11/01 12:00'},\n",
       "   {'text': 'user:How are you getting on with the algebra? , assistant:It is more in depth than regular math, where do you like to travel?',\n",
       "    'time': '2024/11/01 12:09'}]},\n",
       " {'group': 'User shares travel experiences across Europe, expressing interest in visiting Colombia next. Assistant discusses Spain and Madrid, highlighting travel dreams and future retirement plans.',\n",
       "  'children': [{'text': \"user:It is! I've been all over Europe and the East. Do you ever travel with your family? Other than thanksgiving at grama , assistant:Unfortunately no, maybe one day we will\",\n",
       "    'time': '2024/11/01 12:10'},\n",
       "   {'text': 'user:Maybe you could go with Theda Thorpe one day?, assistant:Yes if hed want to go with me, do you have kids of your own',\n",
       "    'time': '2024/11/01 12:11'},\n",
       "   {'text': 'user:What places would you like to visit if you could?, assistant:I really want to back pack across Europe. But, the number one country in Europe I would love to go to is Spain. Where do you want to travel?',\n",
       "    'time': '2024/11/01 12:12'},\n",
       "   {'text': \"user:I've been to Spain a couple of times. It's a great destination. For my next trip, I'm thinking of going to Colombia. I've never been to South America. Where does Theda Thorpe want to travel?, assistant:Theda wants to go to Spain as well. She heard that Madrid is beautiful this time of year. Yeah, Colombia would be amazing. That should be the first place you go once you retire. How much are you looking forward to your retirement? \",\n",
       "    'time': '2024/11/01 12:13'},\n",
       "   {'text': \"user:This month is a great time to visit Madrid. The weather is great and not as many tourist. That's a great idea and I am so very much ready for retirement. Have you thought about what you might want to do?, assistant:Well, I really have not thought about what I want to do because I am only 13 and wont be able to go any time soon unless my parents pay for the trip. I really don't think that will be the case. My parents are more worried about saving for my college tuition then paying for my travels. Although, I don't really blame them.\",\n",
       "    'time': '2024/11/01 12:14'}]},\n",
       " {'group': \"User discusses career aspirations related to photography and writing. Assistant expresses interest in photography and potential for collaboration on a children's book.\",\n",
       "  'children': [{'text': \"user:Sorry, I wasn't clear. I meant what you are interested in for a career. , assistant:Oh, for my career??? I think I want to do something with Photography. It would be amazing to travel the world and take picture for a magazine like National Geographic.\",\n",
       "    'time': '2024/11/01 12:15'},\n",
       "   {'text': \"user:Wouldn't that be the life?! Maybe as a backup, you could consider being a librarian. Books are filled with journeys., assistant:Yeah, that is true. I love reading books. By the way, do you have any new titles that I should read?\",\n",
       "    'time': '2024/11/01 12:16'},\n",
       "   {'text': 'user:What genre do you enjoy?, assistant:I really like thrillers and Sci-Fi. But anything that is good',\n",
       "    'time': '2024/11/01 12:17'},\n",
       "   {'text': \"user:I've been thinking about writing my own children's book, after spending so long working with books it might be time to try and make my own., assistant:Ooooh! That sounds so cool. Do you know what you want the book to have on the cover? I could take the cover photo maybe? For your book?\",\n",
       "    'time': '2024/11/01 12:18'}]},\n",
       " {'group': \"User inquires about reading preferences, and assistant reveals a love for thrillers and Sci-Fi. Assistant also mentions past photography experiences hindered by a bully's actions.\",\n",
       "  'children': [{'text': 'user:What a great idea! Do you take photos of all the places you go with your friends?, assistant:No, a bully named Rico threw my camera in the gutter last week so now I can only take “mind” pictures that I develop in my dreams.',\n",
       "    'time': '2024/11/01 12:19'}]},\n",
       " {'group': 'User, a librarian, expresses love for kids, while assistant talks about their school librarian and soccer coach. Both have positive views on their roles.',\n",
       "  'children': [{'text': 'user:Oh no, how old are you. I am 60, retiring in a few years., assistant:13. I have an older brother who is 17.',\n",
       "    'time': '2024/11/01 12:01'},\n",
       "   {'text': 'user:Nice, I love kids, I work as a librarian, assistant:I like our school librarian. She s also our soccer coach. Really nice.',\n",
       "    'time': '2024/11/01 12:02'}]},\n",
       " {'group': 'User compliments the assistant, who reveals a crush on a classmate, Theda Thorpe, indicating typical childhood feelings.',\n",
       "  'children': [{'text': 'user:Haha, you sound like a great kid., assistant:I guess. I only wish theda thorpe would go steady with me.',\n",
       "    'time': '2024/11/01 12:07'}]}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_mem.show_group_and_children()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'search_times': 2,\n",
       " 'used_keywords': ['Hey, remember that time we talked about my job? Do you happen to recall how much I told you I make annually?'],\n",
       " 'searched_memory': [{'text': \"User asks about assistant's knowledge and relationship status. Assistant jokes about dislike for orange clothing and shares financial challenges.\",\n",
       "   'time': '2024/11/01 12:03'},\n",
       "  {'text': \"Discussion on student loans and job opportunities. User expresses support for assistant's job in research, while sharing pride in her husband's promotion to Chief of Surgery. Both emphasize the importance of taking one step at a time in their careers.\",\n",
       "   'time': '2024/11/01 12:15'}],\n",
       " 'thought': \"While there are discussions about jobs and financial challenges, the user's exact annual income is not disclosed in the retrieved information.\",\n",
       " 'evidence': [{'text': \"Discussion on student loans and job opportunities. User expresses support for assistant's job in research, while sharing pride in her husband's promotion to Chief of Surgery. Both emphasize the importance of taking one step at a time in their careers.\"},\n",
       "  {'text': \"User expresses support for assistant's job in research, while sharing pride in her husband's promotion to Chief of Surgery.\"}]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=22\n",
    "eval(answer_df['long_mem_recall_result'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval(answer_df['long_mem_result'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You mentioned you'd like to go to culinary school!\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_df['gold_answer'][index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"msc_self_instruct.jsonl\", lines=True)\n",
    "\n",
    "s_answer_df = pd.DataFrame()\n",
    "s_answer_df['dialog'] = None\n",
    "s_answer_df['question'] = None\n",
    "s_answer_df['gold_answer'] = None\n",
    "s_answer_df['short_mem_result'] = None\n",
    "s_answer_df['short_mem_answer'] = None\n",
    "s_answer_df['short_mem_f1'] = None\n",
    "s_answer_df['short_mem_rc'] = None\n",
    "s_answer_df['short_mem_pre'] = None\n",
    "\n",
    "for i in range(500):\n",
    "    # Add dialog\n",
    "    current_time = datetime.strptime(\"2024/11/1 12:00\", \"%Y/%m/%d %H:%M\")\n",
    "    dialog_data = []\n",
    "    for dialog_session in df['previous_dialogs'][i]:\n",
    "        session = []\n",
    "        for count in range(int(len(dialog_session['dialog'])/2)):\n",
    "            chat_log = {\"assistant\":f\"{dialog_session['dialog'][2*count]['text']}\", \n",
    "                        \"user\":f\"{dialog_session['dialog'][2*count+1]['text']}\", \n",
    "                        \"time\":current_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")}\n",
    "            session.append(chat_log)\n",
    "            current_time = current_time + timedelta(minutes=1)\n",
    "        dialog_data.append(session)\n",
    "    s_answer_df.loc[i, 'dialog'] = str(dialog_data)\n",
    "    \n",
    "    # Add question & answer\n",
    "    s_answer_df.loc[i, 'question'] = f\"user:{df['self_instruct'][i]['B']}\"\n",
    "    s_answer_df.loc[i, 'gold_answer'] = f\"{df['self_instruct'][i]['A']}\"\n",
    "s_answer_df.to_json(\"s_MSC_datasets.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s_answer_df = pd.read_json(\"s_MSC_datasets.json\", lines=True)\n",
    "# s_answer_df = pd.read_json(\"s_MSC_eval.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from short_memory.component import WeaviateShortMemory\n",
    "short_mem = WeaviateShortMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def llm_create(prompt):\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "\n",
    "answer_prompt = \"\"\"Base on the following document and answer the question.\n",
    "Try use origin text in the evidence field to repeat a brief answer.\n",
    "\n",
    "Question:{question}\n",
    "\n",
    "Document:{docs}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list = []\n",
    "for i in range(100):\n",
    "    print(f'==={i}===')\n",
    "    try:\n",
    "        # generate result\n",
    "        short_mem.del_memory()\n",
    "        dialogs = []\n",
    "        for dialog_session in eval(s_answer_df.loc[i, 'dialog']):\n",
    "            dialogs.extend(dialog_session)\n",
    "        short_mem.add_chatlogs(dialogs)\n",
    "        question = f\"{answer_df.loc[i, 'question']}\"\n",
    "        s_answer_df.loc[i, 'short_mem_result'] = str(short_mem.get_memory(question))\n",
    "        \n",
    "        # response\n",
    "        p = answer_prompt.format(question=answer_df.loc[i, 'question'], docs=answer_df.loc[i, 'short_mem_result'])\n",
    "        short_mem_answer = llm_create(p)\n",
    "        s_answer_df.loc[i, 'short_mem_answer'] = short_mem_answer\n",
    "    except Exception as e:\n",
    "        error_list.append(i)\n",
    "        print(f'----error:{e}----')\n",
    "    if (i+1)%20==0:\n",
    "        s_answer_df.to_json(\"s_MSC_eval.json\", orient=\"records\", lines=True)\n",
    "s_answer_df.to_json(\"s_MSC_eval.json\", orient=\"records\", lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
