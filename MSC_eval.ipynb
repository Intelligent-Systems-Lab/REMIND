{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "df = pd.read_json(\"msc_self_instruct.jsonl\", lines=True)\n",
    "\n",
    "answer_df = pd.DataFrame()\n",
    "answer_df['dialog'] = None\n",
    "answer_df['question'] = None\n",
    "answer_df['gold_answer'] = None\n",
    "answer_df['long_mem_result'] = None\n",
    "answer_df['long_mem_answer'] = None\n",
    "answer_df['long_mem_f1'] = None\n",
    "answer_df['long_mem_rc'] = None\n",
    "answer_df['long_mem_pre'] = None\n",
    "answer_df['long_mem_recall_result'] = None\n",
    "answer_df['long_mem_recall_answer'] = None\n",
    "answer_df['long_mem_recall_f1'] = None\n",
    "answer_df['long_mem_recall_rc'] = None\n",
    "answer_df['long_mem_recall_pre'] = None\n",
    "\n",
    "for i in range(500):\n",
    "    # Add dialog\n",
    "    current_time = datetime.strptime(\"2024/11/1 12:00\", \"%Y/%m/%d %H:%M\")\n",
    "    dialog_data = []\n",
    "    for dialog_session in df['previous_dialogs'][i]:\n",
    "        session = []\n",
    "        for count in range(int(len(dialog_session['dialog'])/2)):\n",
    "            chat_log = {\"text\":f\"Allen:{dialog_session['dialog'][2*count]['text']}, Jack:{dialog_session['dialog'][2*count+1]['text']}\", \"time\":current_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")}\n",
    "            session.append(chat_log)\n",
    "            current_time = current_time + timedelta(minutes=1)\n",
    "        dialog_data.append(session)\n",
    "    answer_df.loc[i, 'dialog'] = str(dialog_data)\n",
    "    \n",
    "    # Add question & answer\n",
    "    answer_df.loc[i, 'question'] = f\"Jack:{df['self_instruct'][i]['B']}\"\n",
    "    answer_df.loc[i, 'gold_answer'] = f\"{df['self_instruct'][i]['A']}\"\n",
    "answer_df.to_json(\"MSC_datasets.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "answer_df = pd.read_json(\"MSC_datasets.json\", lines=True)\n",
    "# answer_df = pd.read_json(\"MSC_eval.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from long_memory.component import WeaviateLongMemory\n",
    "long_mem = WeaviateLongMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def llm_create(prompt):\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "\n",
    "other_instruct=\"\"\"Your role is Allen, Jack will ask some question about you, you need to find relative memory in Allen's memory.\n",
    "here's some guide for you. similar_snippets is original memory, related_summaries and closest_summary are compressed memory for suggestion, \n",
    "If you see some relative content from related_summaries, you can use jump to related_summaries and get original memory,\n",
    "when you use retry, you can use specific things to search not just a question.\n",
    "when you need to write evidence, try put original dialog into evidence field, not compressed memory\"\"\"\n",
    "\n",
    "answer_prompt = \"\"\"Base on the following document and answer the question.\n",
    "You are Allen, try use origin text in the evidence field to repeat a brief answer.\n",
    "\n",
    "Question:{question}\n",
    "\n",
    "Document:{docs}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list = []\n",
    "for i in range(100):\n",
    "    print(f'==={i}===')\n",
    "    try:\n",
    "        # generate result\n",
    "        long_mem.del_memory()\n",
    "        dialogs = []\n",
    "        for dialog_session in eval(answer_df.loc[i, 'dialog']):\n",
    "            dialogs.extend(dialog_session)\n",
    "        long_mem.add_chat_logs(dialogs)\n",
    "        question = f\"{answer_df.loc[i, 'question']}\"\n",
    "        answer_df.loc[i, 'long_mem_result'] = str(long_mem.get_memory(question, recall=False))\n",
    "        answer_df.loc[i, 'long_mem_recall_result'] = str(long_mem.get_memory(question, recall=True, other_instruct=other_instruct))\n",
    "        \n",
    "        # response\n",
    "        p = answer_prompt.format(question=answer_df.loc[i, 'question'], docs=answer_df.loc[i, 'long_mem_result'])\n",
    "        long_mem_answer = llm_create(p)\n",
    "        answer_df.loc[i, 'long_mem_answer'] = long_mem_answer\n",
    "        \n",
    "        p = answer_prompt.format(question=answer_df.loc[i, 'question'], docs=answer_df.loc[i, 'long_mem_recall_result'])\n",
    "        long_mem_recall_answer = llm_create(p)\n",
    "        answer_df.loc[i, 'long_mem_recall_answer'] = long_mem_recall_answer\n",
    "    except Exception as e:\n",
    "        error_list.append(i)\n",
    "        print(f'----error:{e}----')\n",
    "    if (i+1)%20==0:\n",
    "        answer_df.to_json(\"MSC_eval.json\", orient=\"records\", lines=True)\n",
    "answer_df.to_json(\"MSC_eval.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'search times': 1,\n",
       " 'used queries': ['Jack:Hey, remember that time we talked about our favorite movies? What was yours?'],\n",
       " 'searched memory': [{'text': 'Allen and Jack discuss their preferences in movie genres, primarily comedies and nature documentaries.',\n",
       "   'time': '2024/11/01 12:15'}],\n",
       " 'thought': \"I found detailed memories of our conversation about movie preferences, highlighting that I enjoy nature documentaries, particularly the BBC series 'Blue Planet II', while Jack enjoys comedies like 'Clueless'.\",\n",
       " 'evidence': [{'text': \"Allen: I haven't. I'm not really into comedies, because I don't really have a sophisticated sense of humor. What genre do you think your first book will be?, Jack: it would be the kind of comedy that clueless is. Do you not think of clueless as a comedy?\"},\n",
       "  {'text': \"Allen: Yeah, I think so. But what I enjoy the most is nature documentaries. I like learning new things, and so I'll sometimes spend the whole day knitting and watching wildlife on tv!\"},\n",
       "  {'text': \"Allen: My favorite is Blue Planet II. I think the music is just top notch. And I love the footage of the deep sea creatures! They're so alien-looking.\"}]}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=6\n",
    "eval(answer_df['long_mem_recall_result'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialog</th>\n",
       "      <th>question</th>\n",
       "      <th>gold_answer</th>\n",
       "      <th>long_mem_result</th>\n",
       "      <th>long_mem_answer</th>\n",
       "      <th>long_mem_f1</th>\n",
       "      <th>long_mem_rc</th>\n",
       "      <th>long_mem_pre</th>\n",
       "      <th>long_mem_recall_result</th>\n",
       "      <th>long_mem_recall_answer</th>\n",
       "      <th>long_mem_recall_f1</th>\n",
       "      <th>long_mem_recall_rc</th>\n",
       "      <th>long_mem_recall_pre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[{'text': \"Allen:Hi! How are you doing tonigh...</td>\n",
       "      <td>Jack:Hey, remember that time we talked about m...</td>\n",
       "      <td>Taylor Swift!</td>\n",
       "      <td>{'closest_summary': {'text': 'Allen and Jack t...</td>\n",
       "      <td>The document does not mention any specific art...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'search times': 4, 'used queries': ['Jack:Hey...</td>\n",
       "      <td>I mentioned that I could get into Taylor Swift.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[{'text': 'Allen:Hello, how are you doing?, J...</td>\n",
       "      <td>Jack:Hey, remember that time we talked about o...</td>\n",
       "      <td>I eat a fresh and raw diet to save on groceries.</td>\n",
       "      <td>{'closest_summary': {'text': 'Allen shares his...</td>\n",
       "      <td>Allen saved money by primarily eating a fresh ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'search times': 1, 'used queries': ['Jack:Hey...</td>\n",
       "      <td>I mentioned that I mostly eat a fresh and raw ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[{'text': 'Allen:Hello what are doing today?,...</td>\n",
       "      <td>Jack:Hey, remember that time we talked about o...</td>\n",
       "      <td>I used to work in the human services field.</td>\n",
       "      <td>{'closest_summary': {'text': \"Allen and Jack d...</td>\n",
       "      <td>I used to work in the human services field.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'search times': 1, 'used queries': ['Jack:Hey...</td>\n",
       "      <td>Allen used to work in the human services field.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[{'text': \"Allen:How are you? I'm tired of my...</td>\n",
       "      <td>Jack:Hey, remember that time we talked about o...</td>\n",
       "      <td>Burger King!</td>\n",
       "      <td>{'closest_summary': {'text': 'Conversation abo...</td>\n",
       "      <td>Allen: I have a part-time job at Burger King.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'search times': 1, 'used queries': [\"Jack:Hey...</td>\n",
       "      <td>Sure! I work at Burger King.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[{'text': 'Allen:Hi, how are you doing today?...</td>\n",
       "      <td>Jack:Hey, remember that time we talked about o...</td>\n",
       "      <td>Three miles!</td>\n",
       "      <td>{'closest_summary': {'text': 'Allen and Jack d...</td>\n",
       "      <td>I mentioned that I like to walk three miles fo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'search times': 1, 'used queries': ['Jack:Hey...</td>\n",
       "      <td>I mentioned that I like to walk for a small wo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              dialog  \\\n",
       "0  [[{'text': \"Allen:Hi! How are you doing tonigh...   \n",
       "1  [[{'text': 'Allen:Hello, how are you doing?, J...   \n",
       "2  [[{'text': 'Allen:Hello what are doing today?,...   \n",
       "3  [[{'text': \"Allen:How are you? I'm tired of my...   \n",
       "4  [[{'text': 'Allen:Hi, how are you doing today?...   \n",
       "\n",
       "                                            question  \\\n",
       "0  Jack:Hey, remember that time we talked about m...   \n",
       "1  Jack:Hey, remember that time we talked about o...   \n",
       "2  Jack:Hey, remember that time we talked about o...   \n",
       "3  Jack:Hey, remember that time we talked about o...   \n",
       "4  Jack:Hey, remember that time we talked about o...   \n",
       "\n",
       "                                        gold_answer  \\\n",
       "0                                     Taylor Swift!   \n",
       "1  I eat a fresh and raw diet to save on groceries.   \n",
       "2       I used to work in the human services field.   \n",
       "3                                      Burger King!   \n",
       "4                                      Three miles!   \n",
       "\n",
       "                                     long_mem_result  \\\n",
       "0  {'closest_summary': {'text': 'Allen and Jack t...   \n",
       "1  {'closest_summary': {'text': 'Allen shares his...   \n",
       "2  {'closest_summary': {'text': \"Allen and Jack d...   \n",
       "3  {'closest_summary': {'text': 'Conversation abo...   \n",
       "4  {'closest_summary': {'text': 'Allen and Jack d...   \n",
       "\n",
       "                                     long_mem_answer  long_mem_f1  \\\n",
       "0  The document does not mention any specific art...          NaN   \n",
       "1  Allen saved money by primarily eating a fresh ...          NaN   \n",
       "2        I used to work in the human services field.          NaN   \n",
       "3      Allen: I have a part-time job at Burger King.          NaN   \n",
       "4  I mentioned that I like to walk three miles fo...          NaN   \n",
       "\n",
       "   long_mem_rc  long_mem_pre  \\\n",
       "0          NaN           NaN   \n",
       "1          NaN           NaN   \n",
       "2          NaN           NaN   \n",
       "3          NaN           NaN   \n",
       "4          NaN           NaN   \n",
       "\n",
       "                              long_mem_recall_result  \\\n",
       "0  {'search times': 4, 'used queries': ['Jack:Hey...   \n",
       "1  {'search times': 1, 'used queries': ['Jack:Hey...   \n",
       "2  {'search times': 1, 'used queries': ['Jack:Hey...   \n",
       "3  {'search times': 1, 'used queries': [\"Jack:Hey...   \n",
       "4  {'search times': 1, 'used queries': ['Jack:Hey...   \n",
       "\n",
       "                              long_mem_recall_answer  long_mem_recall_f1  \\\n",
       "0    I mentioned that I could get into Taylor Swift.                 NaN   \n",
       "1  I mentioned that I mostly eat a fresh and raw ...                 NaN   \n",
       "2    Allen used to work in the human services field.                 NaN   \n",
       "3                       Sure! I work at Burger King.                 NaN   \n",
       "4  I mentioned that I like to walk for a small wo...                 NaN   \n",
       "\n",
       "   long_mem_recall_rc  long_mem_recall_pre  \n",
       "0                 NaN                  NaN  \n",
       "1                 NaN                  NaN  \n",
       "2                 NaN                  NaN  \n",
       "3                 NaN                  NaN  \n",
       "4                 NaN                  NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Short memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(\"msc_self_instruct.jsonl\", lines=True)\n",
    "\n",
    "s_answer_df = pd.DataFrame()\n",
    "s_answer_df['dialog'] = None\n",
    "s_answer_df['question'] = None\n",
    "s_answer_df['gold_answer'] = None\n",
    "s_answer_df['short_mem_result'] = None\n",
    "s_answer_df['short_mem_answer'] = None\n",
    "s_answer_df['short_mem_f1'] = None\n",
    "s_answer_df['short_mem_rc'] = None\n",
    "s_answer_df['short_mem_pre'] = None\n",
    "\n",
    "for i in range(500):\n",
    "    # Add dialog\n",
    "    current_time = datetime.strptime(\"2024/11/1 12:00\", \"%Y/%m/%d %H:%M\")\n",
    "    dialog_data = []\n",
    "    for dialog_session in df['previous_dialogs'][i]:\n",
    "        session = []\n",
    "        for count in range(int(len(dialog_session['dialog'])/2)):\n",
    "            chat_log = {\"assistant\":f\"{dialog_session['dialog'][2*count]['text']}\", \n",
    "                        \"user\":f\"{dialog_session['dialog'][2*count+1]['text']}\", \n",
    "                        \"time\":current_time.strftime(\"%Y-%m-%dT%H:%M:%SZ\")}\n",
    "            session.append(chat_log)\n",
    "            current_time = current_time + timedelta(minutes=1)\n",
    "        dialog_data.append(session)\n",
    "    s_answer_df.loc[i, 'dialog'] = str(dialog_data)\n",
    "    \n",
    "    # Add question & answer\n",
    "    s_answer_df.loc[i, 'question'] = f\"user:{df['self_instruct'][i]['B']}\"\n",
    "    s_answer_df.loc[i, 'gold_answer'] = f\"{df['self_instruct'][i]['A']}\"\n",
    "s_answer_df.to_json(\"s_MSC_datasets.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "answer_df = pd.read_json(\"s_MSC_datasets.json\", lines=True)\n",
    "# answer_df = pd.read_json(\"s_MSC_eval.json\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from short_memory.component import WeaviateShortMemory\n",
    "short_mem = WeaviateShortMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def llm_create(prompt):\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "        )\n",
    "        return completion.choices[0].message.content\n",
    "\n",
    "answer_prompt = \"\"\"Base on the following document and answer the question.\n",
    "Try use origin text in the evidence field to repeat a brief answer.\n",
    "\n",
    "Question:{question}\n",
    "\n",
    "Document:{docs}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_answer_df = pd.read_json(\"s_MSC_datasets.json\", lines=True)\n",
    "error_list = []\n",
    "for i in range(100):\n",
    "    print(f'==={i}===')\n",
    "    try:\n",
    "        # generate result\n",
    "        short_mem.del_memory()\n",
    "        dialogs = []\n",
    "        for dialog_session in eval(s_answer_df.loc[i, 'dialog']):\n",
    "            dialogs.extend(dialog_session)\n",
    "        short_mem.add_chatlogs(dialogs)\n",
    "        question = f\"{answer_df.loc[i, 'question']}\"\n",
    "        s_answer_df.loc[i, 'short_mem_result'] = str(short_mem.get_memory(question))\n",
    "        \n",
    "        # response\n",
    "        p = answer_prompt.format(question=answer_df.loc[i, 'question'], docs=answer_df.loc[i, 'short_mem_result'])\n",
    "        short_mem_answer = llm_create(p)\n",
    "        s_answer_df.loc[i, 'short_mem_answer'] = short_mem_answer\n",
    "    except Exception as e:\n",
    "        error_list.append(i)\n",
    "        print(f'----error:{e}----')\n",
    "    if (i+1)%20==0:\n",
    "        s_answer_df.to_json(\"s_MSC_eval.json\", orient=\"records\", lines=True)\n",
    "s_answer_df.to_json(\"s_MSC_eval.json\", orient=\"records\", lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
