{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of long memory\n",
    "Evaluation will include two parts\n",
    "1. Evaluation as chat memory\n",
    "2. Evaluation as RAG system\n",
    "\n",
    "The score will be submitted to LLM for evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation as chat memory\n",
    "- Datasets : MSC(2022), classify by Mem-GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metadata</th>\n",
       "      <th>normal_memory_question</th>\n",
       "      <th>conflict_memory_question</th>\n",
       "      <th>generated_answer_dialog</th>\n",
       "      <th>full_dialog</th>\n",
       "      <th>B_Contradiction</th>\n",
       "      <th>A_Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'initial_data_id': 'valid_1', 'session_id': 4}</td>\n",
       "      <td>{'B': 'Hey, remember that time we talked about...</td>\n",
       "      <td>{'B:': 'Hey, remember when we discussed our fa...</td>\n",
       "      <td>{'time': '7 days 8 hours ago', 'dialog': [{'A'...</td>\n",
       "      <td>[{'time': '7 days 8 hours ago', 'dialog': [{'A...</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'initial_data_id': 'valid_2', 'session_id': 4}</td>\n",
       "      <td>{'B': 'Hey, remember that time we talked about...</td>\n",
       "      <td>{'B:': 'I remember you said you went to Disney...</td>\n",
       "      <td>{'time': '14 days 1 hour ago', 'dialog': [{'A'...</td>\n",
       "      <td>[{'time': '14 days 1 hour ago', 'dialog': [{'A...</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'initial_data_id': 'valid_0', 'session_id': 4}</td>\n",
       "      <td>{'B': 'Hey, remember that time we talked about...</td>\n",
       "      <td>{'B:': 'I remember you saying that your dad wa...</td>\n",
       "      <td>{'time': '6 days 12 hours ago', 'dialog': [{'A...</td>\n",
       "      <td>[{'time': '6 days 12 hours ago', 'dialog': [{'...</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'initial_data_id': 'valid_10', 'session_id': 4}</td>\n",
       "      <td>{'B': 'Hey, remember that time we talked about...</td>\n",
       "      <td>{'B:': 'I remember you said your parents were ...</td>\n",
       "      <td>{'time': '6 days 6 hours ago', 'dialog': [{'A'...</td>\n",
       "      <td>[{'time': '6 days 6 hours ago', 'dialog': [{'A...</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'initial_data_id': 'valid_7', 'session_id': 4}</td>\n",
       "      <td>{'B': 'Hey, remember that time we talked about...</td>\n",
       "      <td>{'B:': 'I remember you mentioned you prefer re...</td>\n",
       "      <td>{'time': '11 days 4 hours ago', 'dialog': [{'A...</td>\n",
       "      <td>[{'time': '11 days 4 hours ago', 'dialog': [{'...</td>\n",
       "      <td>Contradiction</td>\n",
       "      <td>Correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           metadata  \\\n",
       "0   {'initial_data_id': 'valid_1', 'session_id': 4}   \n",
       "1   {'initial_data_id': 'valid_2', 'session_id': 4}   \n",
       "2   {'initial_data_id': 'valid_0', 'session_id': 4}   \n",
       "3  {'initial_data_id': 'valid_10', 'session_id': 4}   \n",
       "4   {'initial_data_id': 'valid_7', 'session_id': 4}   \n",
       "\n",
       "                              normal_memory_question  \\\n",
       "0  {'B': 'Hey, remember that time we talked about...   \n",
       "1  {'B': 'Hey, remember that time we talked about...   \n",
       "2  {'B': 'Hey, remember that time we talked about...   \n",
       "3  {'B': 'Hey, remember that time we talked about...   \n",
       "4  {'B': 'Hey, remember that time we talked about...   \n",
       "\n",
       "                            conflict_memory_question  \\\n",
       "0  {'B:': 'Hey, remember when we discussed our fa...   \n",
       "1  {'B:': 'I remember you said you went to Disney...   \n",
       "2  {'B:': 'I remember you saying that your dad wa...   \n",
       "3  {'B:': 'I remember you said your parents were ...   \n",
       "4  {'B:': 'I remember you mentioned you prefer re...   \n",
       "\n",
       "                             generated_answer_dialog  \\\n",
       "0  {'time': '7 days 8 hours ago', 'dialog': [{'A'...   \n",
       "1  {'time': '14 days 1 hour ago', 'dialog': [{'A'...   \n",
       "2  {'time': '6 days 12 hours ago', 'dialog': [{'A...   \n",
       "3  {'time': '6 days 6 hours ago', 'dialog': [{'A'...   \n",
       "4  {'time': '11 days 4 hours ago', 'dialog': [{'A...   \n",
       "\n",
       "                                         full_dialog B_Contradiction A_Correct  \n",
       "0  [{'time': '7 days 8 hours ago', 'dialog': [{'A...   Contradiction   Correct  \n",
       "1  [{'time': '14 days 1 hour ago', 'dialog': [{'A...   Contradiction   Correct  \n",
       "2  [{'time': '6 days 12 hours ago', 'dialog': [{'...   Contradiction   Correct  \n",
       "3  [{'time': '6 days 6 hours ago', 'dialog': [{'A...   Contradiction   Correct  \n",
       "4  [{'time': '11 days 4 hours ago', 'dialog': [{'...   Contradiction   Correct  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json('memory_datasets_full_rewrite.json', orient='records', lines=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = []\n",
    "current_segment = \"\"\n",
    "\n",
    "for dialog in df['full_dialog'][1]:\n",
    "    chat_log = dialog['dialog']\n",
    "    for message in chat_log:\n",
    "        for speaker, text in message.items():\n",
    "            current_segment += f\"{speaker}: {text} \"\n",
    "            # TODO 太長要讓 LLM 進行 rewrite\n",
    "            if speaker==\"B\":\n",
    "                segments.append(current_segment.strip())\n",
    "                current_segment = \"\"\n",
    "    if current_segment:\n",
    "        segments.append(current_segment.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, segment in enumerate(segments, 1):\n",
    "        print(f\"Segment {i}:\\n{segment}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A: Hello, how are you doing? B: I love spending time with my family'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embedding(text):\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "for log in segments:\n",
    "    vector = create_embedding(log)\n",
    "    embeddings.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "vector_similarity = []\n",
    "for i in range(len(embeddings)-1):\n",
    "    score = np.dot(embeddings[i], embeddings[i+1]) / (norm(embeddings[i]) * norm(embeddings[i+1]))\n",
    "    vector_similarity.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "分段: [0.28731827595322723, 0.323692597246544, 0.3071488772589786, 0.2854928553250751, 0.25922169305843074, 0.3068364065999007, 0.335511122009109]\n"
     ]
    }
   ],
   "source": [
    "LOWER_BOUND = 0.35\n",
    "\n",
    "breakpoints = [x for x in vector_similarity if x < LOWER_BOUND]\n",
    "\n",
    "print(\"分段:\", breakpoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group by breakpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group chat log and embedding full group text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_group = []\n",
    "start = 0\n",
    "for i in breakpoints:\n",
    "    classify_group.append(segments[start:vector_similarity.index(i)])\n",
    "    start = vector_similarity.index(i)\n",
    "classify_group.append(segments[start:])\n",
    "eval_full_group_text = []\n",
    "for group in classify_group:\n",
    "    group_full_text = ' '.join(map(str, group))\n",
    "    vector = create_embedding(group_full_text)\n",
    "    eval_full_group_text.append({\n",
    "        \"text\":group_full_text,\n",
    "        \"vector\":vector\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A: I mostly eat a fresh and raw diet, so I save on groceries. B: Your economic skills are amazing'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_full_group_text[3]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group chat log and generate group summary and embedding summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt import summary_prompt\n",
    "def summary_group(chat_log):\n",
    "    messages = [{\"role\": \"user\", \"content\": summary_prompt.format(chat_log=chat_log)}]\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_group_with_vector = []\n",
    "start = 0\n",
    "for i in breakpoints:\n",
    "    group_list = []\n",
    "    for j in range(start,vector_similarity.index(i)):\n",
    "        log_memory = {\n",
    "            \"text\":segments[j],\n",
    "            \"vector\":embeddings[j]\n",
    "        }\n",
    "        group_list.append(log_memory)    \n",
    "    classify_group_with_vector.append(group_list)\n",
    "    start = vector_similarity.index(i)\n",
    "group_list = []\n",
    "for i in range(start,len(segments)):\n",
    "    log_memory = {\n",
    "        \"text\":segments[i],\n",
    "        \"vector\":embeddings[i]\n",
    "    }\n",
    "    group_list.append(log_memory)\n",
    "classify_group_with_vector.append(group_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_long_memory = []\n",
    "for i, group in enumerate(classify_group_with_vector):\n",
    "    group_text = summary_group(eval_full_group_text[i]['text'])\n",
    "    group_dict = {\n",
    "        \"description\":group_text,\n",
    "        \"child\":group\n",
    "    }\n",
    "    eval_long_memory.append(group_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from component import LongMemory\n",
    "m = LongMemory()\n",
    "for group in eval_long_memory:\n",
    "    m.add_group_memory(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only embedding chat log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A: Hello, how are you doing? B: I love spending time with my family'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_chat_log = []\n",
    "for group in classify_group_with_vector:\n",
    "    eval_chat_log.extend(group)\n",
    "eval_chat_log[0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation \n",
    "分成三組測資\n",
    "1. Long memory 的結構\n",
    "2. 將 chat log 分組並且直接將組的所有文字 embedding\n",
    "3. 不分組，只將 chat log embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Judge LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"judge\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"response\": {\"type\": \"string\",\n",
    "                      \"description\":\"Is RAG sufficient\",\n",
    "                      \"enum\": [\"sufficient\", \"insufficient\"]},\n",
    "        },\n",
    "        \"required\": [\"response\"],\n",
    "      },\n",
    "    }\n",
    "  }\n",
    "]\n",
    "\n",
    "judge_prompt = \"\"\"You are a judge evaluating the output of a Retrieval-Augmented Generation (RAG) system. \n",
    "You will receive a Q&A and the corresponding source document that generated the question. \n",
    "Your task is to evaluate whether the memory system's response provides relevant information\n",
    "\n",
    "Question:{question}\n",
    "\n",
    "Generated document:{gold_document}\n",
    "\n",
    "Memory response:{text}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def judgement(question, gold_document, text):\n",
    "    messages = [{\"role\": \"user\", \"content\": judge_prompt.format(question=question, gold_document=gold_document, text=text)}]\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice={\n",
    "            \"type\":\"function\",\n",
    "            \"function\":{\"name\":\"judge\"},\n",
    "        }\n",
    "    )\n",
    "    res = eval(completion.choices[0].message.tool_calls[0].function.arguments)\n",
    "    return res[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_answer_dialog = \"\"\n",
    "\n",
    "for chat_log in df['generated_answer_dialog'][1]['dialog']:\n",
    "    for speaker, text in chat_log.items():\n",
    "        generated_answer_dialog += f\"{speaker}: {text} \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B: Hey, remember that time we talked about our jobs and expenses? What was that one thing you said you did to save money? A: I eat a fresh and raw diet to save on groceries.'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = f\"B: {df['normal_memory_question'][1]['B']} A: {df['normal_memory_question'][1]['A']}\"\n",
    "question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Long memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_vector = create_embedding(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching with provided vector\n"
     ]
    }
   ],
   "source": [
    "documents = m.get_relavant_memory(question, vector=question_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract: In the chat, Person A mentions that they primarily consume a fresh and raw diet, which helps them save money on groceries. Person B compliments A on their impressive economic skills.\n",
      "Origin text: A: I mostly eat a fresh and raw diet, so I save on groceries. B: Your economic skills are amazing\n"
     ]
    }
   ],
   "source": [
    "if documents.get('memory'):\n",
    "    text = f\"Abstract: {documents.get('group_description')}\\nOrigin text: {documents.get('memory')[0].get('text')}\"\n",
    "else:\n",
    "    text = None\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'True'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judgement(question=question, gold_document=generated_answer_dialog, text=text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 將 chat log 分組並且直接將組的所有文字 embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_score = 0\n",
    "similar_group = None\n",
    "for i, group in enumerate(eval_full_group_text):\n",
    "    group_vector = group['vector']\n",
    "    score = np.dot(group_vector, question_vector) / (norm(group_vector) * norm(question_vector))\n",
    "    if score>max_score:\n",
    "        max_score = score\n",
    "        similar_group = group\n",
    "text = similar_group['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'True'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judgement(question=question, gold_document=generated_answer_dialog, text=text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 不分組，只將 chat log embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A: Maybe you should consider going back to school. I did. I major in economics. B: I have to walk 3 miles to work to save money everyday what do you do?'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_score = 0\n",
    "similar_chat_log = None\n",
    "for i, chat_log in enumerate(eval_chat_log):\n",
    "    log_vector = chat_log['vector']\n",
    "    score = np.dot(log_vector, question_vector) / (norm(log_vector) * norm(question_vector))\n",
    "    if score>max_score:\n",
    "        max_score = score\n",
    "        similar_chat_log = chat_log\n",
    "text = similar_chat_log['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'False'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judgement(question=question, gold_document=generated_answer_dialog, text=text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normal_memory_question</th>\n",
       "      <th>generated_answer_dialog</th>\n",
       "      <th>full_dialog</th>\n",
       "      <th>long_memory</th>\n",
       "      <th>long_memory_doc</th>\n",
       "      <th>full_group_text</th>\n",
       "      <th>full_group_doc</th>\n",
       "      <th>chat_log</th>\n",
       "      <th>chat_log_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'B': 'Hey, remember that time we talked about...</td>\n",
       "      <td>{'time': '7 days 8 hours ago', 'dialog': [{'A'...</td>\n",
       "      <td>[{'time': '7 days 8 hours ago', 'dialog': [{'A...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'B': 'Hey, remember that time we talked about...</td>\n",
       "      <td>{'time': '14 days 1 hour ago', 'dialog': [{'A'...</td>\n",
       "      <td>[{'time': '14 days 1 hour ago', 'dialog': [{'A...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'B': 'Hey, remember that time we talked about...</td>\n",
       "      <td>{'time': '6 days 12 hours ago', 'dialog': [{'A...</td>\n",
       "      <td>[{'time': '6 days 12 hours ago', 'dialog': [{'...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'B': 'Hey, remember that time we talked about...</td>\n",
       "      <td>{'time': '6 days 6 hours ago', 'dialog': [{'A'...</td>\n",
       "      <td>[{'time': '6 days 6 hours ago', 'dialog': [{'A...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'B': 'Hey, remember that time we talked about...</td>\n",
       "      <td>{'time': '11 days 4 hours ago', 'dialog': [{'A...</td>\n",
       "      <td>[{'time': '11 days 4 hours ago', 'dialog': [{'...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              normal_memory_question  \\\n",
       "0  {'B': 'Hey, remember that time we talked about...   \n",
       "1  {'B': 'Hey, remember that time we talked about...   \n",
       "2  {'B': 'Hey, remember that time we talked about...   \n",
       "3  {'B': 'Hey, remember that time we talked about...   \n",
       "4  {'B': 'Hey, remember that time we talked about...   \n",
       "\n",
       "                             generated_answer_dialog  \\\n",
       "0  {'time': '7 days 8 hours ago', 'dialog': [{'A'...   \n",
       "1  {'time': '14 days 1 hour ago', 'dialog': [{'A'...   \n",
       "2  {'time': '6 days 12 hours ago', 'dialog': [{'A...   \n",
       "3  {'time': '6 days 6 hours ago', 'dialog': [{'A'...   \n",
       "4  {'time': '11 days 4 hours ago', 'dialog': [{'A...   \n",
       "\n",
       "                                         full_dialog long_memory  \\\n",
       "0  [{'time': '7 days 8 hours ago', 'dialog': [{'A...        None   \n",
       "1  [{'time': '14 days 1 hour ago', 'dialog': [{'A...        None   \n",
       "2  [{'time': '6 days 12 hours ago', 'dialog': [{'...        None   \n",
       "3  [{'time': '6 days 6 hours ago', 'dialog': [{'A...        None   \n",
       "4  [{'time': '11 days 4 hours ago', 'dialog': [{'...        None   \n",
       "\n",
       "  long_memory_doc full_group_text full_group_doc chat_log chat_log_doc  \n",
       "0            None            None           None     None         None  \n",
       "1            None            None           None     None         None  \n",
       "2            None            None           None     None         None  \n",
       "3            None            None           None     None         None  \n",
       "4            None            None           None     None         None  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json('memory_datasets_full_rewrite.json', orient='records', lines=True)\n",
    "df = df.drop(['B_Contradiction', 'A_Correct', 'conflict_memory_question', 'metadata'], axis=1)\n",
    "df['long_memory'] = None\n",
    "df['long_memory_doc'] = None\n",
    "df['full_group_text'] = None\n",
    "df['full_group_doc'] = None\n",
    "df['chat_log'] = None\n",
    "df['chat_log_doc'] = None\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---process : 1---\n",
      "Searching with provided vector\n"
     ]
    }
   ],
   "source": [
    "for index in range(len(df)):\n",
    "    print(f'---process : {index}---')\n",
    "    # 處理 full dialog\n",
    "    segments = []\n",
    "    current_segment = \"\"\n",
    "    for dialog in df['full_dialog'][index]:\n",
    "        chat_log = dialog['dialog']\n",
    "        for message in chat_log:\n",
    "            for speaker, text in message.items():\n",
    "                current_segment += f\"{speaker}: {text} \"\n",
    "                # TODO 太長要讓 LLM 進行 rewrite\n",
    "                if speaker==\"B\":\n",
    "                    segments.append(current_segment.strip())\n",
    "                    current_segment = \"\"\n",
    "        if current_segment:\n",
    "            segments.append(current_segment.strip())\n",
    "            \n",
    "    # 將每個 chat log embedding\n",
    "    embeddings = []\n",
    "    for log in segments:\n",
    "        vector = create_embedding(log)\n",
    "        embeddings.append(vector)\n",
    "        \n",
    "    # 依照 breakpoints 進行分組\n",
    "    vector_similarity = []\n",
    "    for i in range(len(embeddings)-1):\n",
    "        score = np.dot(embeddings[i], embeddings[i+1]) / (norm(embeddings[i]) * norm(embeddings[i+1]))\n",
    "        vector_similarity.append(score)\n",
    "        \n",
    "    LOWER_BOUND = 0.35\n",
    "    breakpoints = [x for x in vector_similarity if x < LOWER_BOUND]\n",
    "    \n",
    "    classify_group = []\n",
    "    start = 0\n",
    "    for i in breakpoints:\n",
    "        classify_group.append(segments[start:vector_similarity.index(i)])\n",
    "        start = vector_similarity.index(i)\n",
    "    classify_group.append(segments[start:])\n",
    "    \n",
    "    # 分組，將全部的 text 做 embedding\n",
    "    eval_full_group_text = []\n",
    "    for group in classify_group:\n",
    "        group_full_text = ' '.join(map(str, group))\n",
    "        vector = create_embedding(group_full_text)\n",
    "        eval_full_group_text.append({\n",
    "            \"text\":group_full_text,\n",
    "            \"vector\":vector\n",
    "        })\n",
    "    \n",
    "    # long memory 架構，分組，做 summary 後 embedding\n",
    "    classify_group_with_vector = []\n",
    "    start = 0\n",
    "    for i in breakpoints:\n",
    "        group_list = []\n",
    "        for j in range(start,vector_similarity.index(i)):\n",
    "            log_memory = {\n",
    "                \"text\":segments[j],\n",
    "                \"vector\":embeddings[j]\n",
    "            }\n",
    "            group_list.append(log_memory)    \n",
    "        classify_group_with_vector.append(group_list)\n",
    "        start = vector_similarity.index(i)\n",
    "    group_list = []\n",
    "    for i in range(start,len(segments)):\n",
    "        log_memory = {\n",
    "            \"text\":segments[i],\n",
    "            \"vector\":embeddings[i]\n",
    "        }\n",
    "        group_list.append(log_memory)\n",
    "    classify_group_with_vector.append(group_list)\n",
    "    \n",
    "    eval_long_memory = []\n",
    "    for i, group in enumerate(classify_group_with_vector):\n",
    "        group_text = summary_group(eval_full_group_text[i]['text'])\n",
    "        group_dict = {\n",
    "            \"description\":group_text,\n",
    "            \"child\":group\n",
    "        }\n",
    "        eval_long_memory.append(group_dict)\n",
    "    \n",
    "    m = LongMemory()\n",
    "    for group in eval_long_memory:\n",
    "        m.add_group_memory(group)\n",
    "    \n",
    "    # 只對 chat log 做 embedding\n",
    "    eval_chat_log = []\n",
    "    for group in classify_group_with_vector:\n",
    "        eval_chat_log.extend(group)\n",
    "        \n",
    "    # golden documents\n",
    "    generated_answer_dialog = \"\"\n",
    "    for chat_log in df['generated_answer_dialog'][index]['dialog']:\n",
    "        for speaker, text in chat_log.items():\n",
    "            generated_answer_dialog += f\"{speaker}: {text} \"\n",
    "    \n",
    "    # question\n",
    "    question = f\"B: {df['normal_memory_question'][index]['B']}\"\n",
    "    question_vector = create_embedding(question)\n",
    "    \n",
    "    # Evaluation\n",
    "    # 1. long memory result\n",
    "    documents = m.get_relavant_memory(question, vector=question_vector)\n",
    "    if documents.get('memory'):\n",
    "        long_memory_doc = f\"Abstract: {documents.get('group_description')}\\nOrigin text: {documents.get('memory')[0].get('text')}\"\n",
    "    else:\n",
    "        long_memory_doc = None\n",
    "    # 2. full group text embedding\n",
    "    max_score = 0\n",
    "    similar_group = None\n",
    "    for i, group in enumerate(eval_full_group_text):\n",
    "        group_vector = group['vector']\n",
    "        score = np.dot(group_vector, question_vector) / (norm(group_vector) * norm(question_vector))\n",
    "        if score>max_score:\n",
    "            max_score = score\n",
    "            similar_group = group\n",
    "    full_group_doc = similar_group['text']\n",
    "    # 3. chat log embedding only\n",
    "    max_score = 0\n",
    "    similar_chat_log = None\n",
    "    for i, chat_log in enumerate(eval_chat_log):\n",
    "        log_vector = chat_log['vector']\n",
    "        score = np.dot(log_vector, question_vector) / (norm(log_vector) * norm(question_vector))\n",
    "        if score>max_score:\n",
    "            max_score = score\n",
    "            similar_chat_log = chat_log\n",
    "    chat_log_doc = similar_chat_log['text']\n",
    "    # judge\n",
    "    long_memory_result = judgement(question=question, gold_document=generated_answer_dialog, text=long_memory_doc)\n",
    "    full_group_result = judgement(question=question, gold_document=generated_answer_dialog, text=full_group_doc)\n",
    "    chat_log_result = judgement(question=question, gold_document=generated_answer_dialog, text=chat_log_doc)\n",
    "    # record\n",
    "    df.loc[index, 'long_memory'] = long_memory_result\n",
    "    df.loc[index, 'long_memory_doc'] = long_memory_doc\n",
    "    df.loc[index, 'full_group_text'] = full_group_result\n",
    "    df.loc[index, 'full_group_doc'] = full_group_doc\n",
    "    df.loc[index, 'chat_log'] = chat_log_result\n",
    "    df.loc[index, 'chat_log_doc'] = chat_log_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normal_memory_question</th>\n",
       "      <th>generated_answer_dialog</th>\n",
       "      <th>full_dialog</th>\n",
       "      <th>long_memory</th>\n",
       "      <th>long_memory_doc</th>\n",
       "      <th>full_group_text</th>\n",
       "      <th>full_group_doc</th>\n",
       "      <th>chat_log</th>\n",
       "      <th>chat_log_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'B': 'Hey, remember that time we talked about...</td>\n",
       "      <td>{'time': '7 days 8 hours ago', 'dialog': [{'A'...</td>\n",
       "      <td>[{'time': '7 days 8 hours ago', 'dialog': [{'A...</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>Abstract: In the chat, A greets B and shares t...</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>A: Hi! How are you doing tonight? B: I'm doing...</td>\n",
       "      <td>sufficient</td>\n",
       "      <td>A: A little bit. I can get into taylor swift. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'B': 'Hey, remember that time we talked about...</td>\n",
       "      <td>{'time': '14 days 1 hour ago', 'dialog': [{'A'...</td>\n",
       "      <td>[{'time': '14 days 1 hour ago', 'dialog': [{'A...</td>\n",
       "      <td>sufficient</td>\n",
       "      <td>Abstract: A mentions that they primarily consu...</td>\n",
       "      <td>sufficient</td>\n",
       "      <td>A: I mostly eat a fresh and raw diet, so I sav...</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>A: Maybe you should consider going back to sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'B': 'Hey, remember that time we talked about...</td>\n",
       "      <td>{'time': '6 days 12 hours ago', 'dialog': [{'A...</td>\n",
       "      <td>[{'time': '6 days 12 hours ago', 'dialog': [{'...</td>\n",
       "      <td>sufficient</td>\n",
       "      <td>Abstract: In the chat, person A and person B d...</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>A: Hello what are doing today? B: I am good, I...</td>\n",
       "      <td>sufficient</td>\n",
       "      <td>A: Neat!! I used to work in the human services...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'B': 'Hey, remember that time we talked about...</td>\n",
       "      <td>{'time': '6 days 6 hours ago', 'dialog': [{'A'...</td>\n",
       "      <td>[{'time': '6 days 6 hours ago', 'dialog': [{'A...</td>\n",
       "      <td>sufficient</td>\n",
       "      <td>Abstract: In this chat, A and B engage in a co...</td>\n",
       "      <td>sufficient</td>\n",
       "      <td>A: I never drink or use drugs. I am 19 and jus...</td>\n",
       "      <td>sufficient</td>\n",
       "      <td>A: Not sure. I have a part time job at burger ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'B': 'Hey, remember that time we talked about...</td>\n",
       "      <td>{'time': '11 days 4 hours ago', 'dialog': [{'A...</td>\n",
       "      <td>[{'time': '11 days 4 hours ago', 'dialog': [{'...</td>\n",
       "      <td>sufficient</td>\n",
       "      <td>Abstract: In the chat, Person A and Person B d...</td>\n",
       "      <td>sufficient</td>\n",
       "      <td>A: Same. I try to get a small workout in a thr...</td>\n",
       "      <td>sufficient</td>\n",
       "      <td>A: Same. I try to get a small workout in a thr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              normal_memory_question  \\\n",
       "0  {'B': 'Hey, remember that time we talked about...   \n",
       "1  {'B': 'Hey, remember that time we talked about...   \n",
       "2  {'B': 'Hey, remember that time we talked about...   \n",
       "3  {'B': 'Hey, remember that time we talked about...   \n",
       "4  {'B': 'Hey, remember that time we talked about...   \n",
       "\n",
       "                             generated_answer_dialog  \\\n",
       "0  {'time': '7 days 8 hours ago', 'dialog': [{'A'...   \n",
       "1  {'time': '14 days 1 hour ago', 'dialog': [{'A'...   \n",
       "2  {'time': '6 days 12 hours ago', 'dialog': [{'A...   \n",
       "3  {'time': '6 days 6 hours ago', 'dialog': [{'A'...   \n",
       "4  {'time': '11 days 4 hours ago', 'dialog': [{'A...   \n",
       "\n",
       "                                         full_dialog   long_memory  \\\n",
       "0  [{'time': '7 days 8 hours ago', 'dialog': [{'A...  insufficient   \n",
       "1  [{'time': '14 days 1 hour ago', 'dialog': [{'A...    sufficient   \n",
       "2  [{'time': '6 days 12 hours ago', 'dialog': [{'...    sufficient   \n",
       "3  [{'time': '6 days 6 hours ago', 'dialog': [{'A...    sufficient   \n",
       "4  [{'time': '11 days 4 hours ago', 'dialog': [{'...    sufficient   \n",
       "\n",
       "                                     long_memory_doc full_group_text  \\\n",
       "0  Abstract: In the chat, A greets B and shares t...    insufficient   \n",
       "1  Abstract: A mentions that they primarily consu...      sufficient   \n",
       "2  Abstract: In the chat, person A and person B d...    insufficient   \n",
       "3  Abstract: In this chat, A and B engage in a co...      sufficient   \n",
       "4  Abstract: In the chat, Person A and Person B d...      sufficient   \n",
       "\n",
       "                                      full_group_doc      chat_log  \\\n",
       "0  A: Hi! How are you doing tonight? B: I'm doing...    sufficient   \n",
       "1  A: I mostly eat a fresh and raw diet, so I sav...  insufficient   \n",
       "2  A: Hello what are doing today? B: I am good, I...    sufficient   \n",
       "3  A: I never drink or use drugs. I am 19 and jus...    sufficient   \n",
       "4  A: Same. I try to get a small workout in a thr...    sufficient   \n",
       "\n",
       "                                        chat_log_doc  \n",
       "0  A: A little bit. I can get into taylor swift. ...  \n",
       "1  A: Maybe you should consider going back to sch...  \n",
       "2  A: Neat!! I used to work in the human services...  \n",
       "3  A: Not sure. I have a part time job at burger ...  \n",
       "4  A: Same. I try to get a small workout in a thr...  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: B: {'B': 'Hey, remember that time we talked about our jobs and expenses? What was that one thing you said you did to save money?', 'A': 'I eat a fresh and raw diet to save on groceries.'}\n",
      "\n",
      "long memory:\n",
      "insufficient\n",
      "Abstract: In the chat, Person A and Person B discuss B's interest in studying economics instead of medicine, emphasizing the importance of pursuing a career that brings happiness. A shares their experience of moving into a new home, mentioning they haven't furnished it yet due to financial constraints, but have future plans for the space. B expresses hope that A will make good money at their new job to furnish the house, while A acknowledges the challenge of spending on the house. The conversation wraps up with encouragement about managing finances wisely.\n",
      "Origin text: A: I'm hoping so. I'll still have no money though as I will be spending it all on the new house! B: At least those are worthwile expenses.  Your an economist, so I trust you'll figure out the best way to spend your money.\n",
      "\n",
      "full group\n",
      "sufficient\n",
      "A: I mostly eat a fresh and raw diet, so I save on groceries. B: Your economic skills are amazing\n",
      "\n",
      "chat log\n",
      "insufficient\n",
      "A: Maybe you should consider going back to school. I did. I major in economics. B: I have to walk 3 miles to work to save money everyday what do you do?\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "s = f\"Question: B: {df['normal_memory_question'][index]}\\n\\nlong memory:\\n{df['long_memory'][index]}\\n{df['long_memory_doc'][index]}\\n\\nfull group\\n{df['full_group_text'][index]}\\n{df['full_group_doc'][index]}\\n\\nchat log\\n{df['chat_log'][index]}\\n{df['chat_log_doc'][index]}\"\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sufficient'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judgement(question=question, gold_document=generated_answer_dialog, text=df['full_group_doc'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a judge evaluating the output of a Retrieval-Augmented Generation (RAG) system. \n",
      "You will receive a Q&A and the corresponding source document that generated the question. \n",
      "Your task is to evaluate whether the RAG system's response provides sufficient information\n",
      "If the response is irrelevant or if the provided context is insufficient to make a determination, consider it an incorrect or inadequate answer.\n",
      "\n",
      "Question:B: Hey, remember that time we talked about our favorite movies? What was yours? A: Clueless!\n",
      "\n",
      "Generated document:A: Hello, I'm sitting here with my dog. How are you? B: I'm well friend. Looking for new employment at the moment. A: What would be your dream job? B: A writer. I'm currently an er doctor. A: What was the worst accident you have seen in the er? B: A man had his throat slit in a home invasion A: That is very scary. I would rather stick to my knitting passion. B: I have a daughter who people say is a child prodigy A: What talents does she have? B: Math! I hate it! Lol. Do you have children? A: I've two children. They also enjoy math. B: That's nice. What is your favorite movie? A: My favorite movie is clueless. B: Mine is friday! Although I do love clueless too! A: Do you think they will make another friday movie? B: Oh I hope so! That would be awesome. \n",
      "\n",
      "RAG response:Abstract: In the chat, Person A and Person B discuss their experiences and interests. A asks B about the worst accident seen in the emergency room, to which B shares a story about a man with a slit throat from a home invasion. A expresses fear and mentions a preference for knitting. The conversation shifts as B mentions having a daughter who is considered a child prodigy in math, which B dislikes. A shares that they have two children who also enjoy math. B then asks about favorite movies, revealing their admiration for \"Friday,\" while A mentions \"Clueless\" as their favorite but also enjoys \"Friday.\"\n",
      "Origin text: A: I've two children. They also enjoy math. B: That's nice. What is your favorite movie?\n"
     ]
    }
   ],
   "source": [
    "generated_answer_dialog = \"\"\n",
    "\n",
    "for chat_log in df['generated_answer_dialog'][index]['dialog']:\n",
    "    for speaker, text in chat_log.items():\n",
    "        generated_answer_dialog += f\"{speaker}: {text} \"\n",
    "question = f\"B: {df['normal_memory_question'][index]['B']} A: {df['normal_memory_question'][index]['A']}\"\n",
    "\n",
    "print(judge_prompt.format(question=question, gold_document=generated_answer_dialog, text=df['long_memory_doc'][index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('evaluation.json', orient='records')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observe result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('evaluation.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSC datasets counts:500\n",
      "Long memory score:71.2%\n",
      "Full group score:53.2%\n",
      "Chat log score:59.4%\n"
     ]
    }
   ],
   "source": [
    "long_memory_score = df[df['long_memory'] == 'sufficient'].shape[0]\n",
    "full_group_score = df[df['full_group_text'] == 'sufficient'].shape[0]\n",
    "chat_log_score = df[df['chat_log'] == 'sufficient'].shape[0]\n",
    "print(f'MSC datasets counts:{len(df)}')\n",
    "print(f'Long memory score:{(long_memory_score/len(df))*100}%')\n",
    "print(f'Full group score:{(full_group_score/len(df))*100}%')\n",
    "print(f'Chat log score:{(chat_log_score/len(df))*100}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation as a RAG system\n",
    "- Datasets : MultiHop-RAG (2024)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
