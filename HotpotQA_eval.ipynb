{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"hotpot_dev_distractor_v1.json\") as f:\n",
    "    datasets = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = datasets[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def llm_create(prompt):\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=messages,\n",
    "        )\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_support_fact_prompts = \"\"\"You are given a query and a list of evidence document.\n",
    "Your task is to find the support fact from the evidence document for the query.\n",
    "Put doc_id into support_fact list if relative to the query.\n",
    "\n",
    "Query:{query}\n",
    "\n",
    "Document:{docs}\n",
    "\n",
    "Output following json format, example:\n",
    "```json\n",
    "{{\n",
    "    \"support_fact\": [\n",
    "        \"a4488301-71ee-47e4-98a1-a26d93ca38a0\",\n",
    "        \"62861a3d-87a7-408b-98bd-688abc8583a6\"\n",
    "    ]\n",
    "}}\n",
    "```\"\"\"\n",
    "\n",
    "answer_prompt = \"\"\"Base on the following document and answer the question.\n",
    "Only answer with no description, answer None if you don't know the answer.\n",
    "\n",
    "Question:{question}\n",
    "\n",
    "Document:{docs}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detect existed deafult user group memory space, loading...\n",
      "Detect existed deafult user child memory space, loading...\n"
     ]
    }
   ],
   "source": [
    "from long_memory.hotpot_component import HotPotWeaviateLongMemory\n",
    "\n",
    "long_mem = HotPotWeaviateLongMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['question_id'] = None\n",
    "df['answer'] = None\n",
    "df['support_fact'] = None\n",
    "df['org_res_from_long_mem'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---1---\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "---2---\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "---3---\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "---4---\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "---5---\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "---6---\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "---7---\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "---8---\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "---9---\n",
      "Detect empty group memory, create memory space...\n",
      "Detect empty child memory, create memory space...\n",
      "can't find this document Local H.\n"
     ]
    }
   ],
   "source": [
    "from weaviate.classes.query import Filter, QueryReference\n",
    "import re\n",
    "\n",
    "for i in range(1, 10):\n",
    "    print(f\"---{i}---\")\n",
    "    sp_fact = []\n",
    "    long_mem.del_memory()\n",
    "    doc_list = datasets[i][\"context\"]\n",
    "    question_id = datasets[i][\"_id\"]\n",
    "    df.loc[i, 'question_id'] = question_id \n",
    "    question = datasets[i][\"question\"]\n",
    "    for doc in doc_list:\n",
    "        long_mem.add_hotpot_doc(doc)\n",
    "    res = long_mem.get_memory(question, recall=True)\n",
    "    df.loc[i, 'org_res_from_long_mem'] = str(res)\n",
    "    answer_res = llm_create(answer_prompt.format(question=question, docs=res))\n",
    "    df.loc[i, 'answer'] = answer_res\n",
    "    response = llm_create(find_support_fact_prompts.format(query=question, docs=res))\n",
    "    json_res = json.loads(re.search(r\"```json(.*?)```\", response, re.DOTALL).group(1).strip())\n",
    "    evidence_doc_id = json_res[\"support_fact\"]\n",
    "    for doc_id in evidence_doc_id:\n",
    "        try:\n",
    "            evidence_doc = long_mem.child_class.query.fetch_objects(filters=Filter.by_id().equal(doc_id), return_references=[QueryReference(link_on=\"parent\",return_properties=[\"doc_name\"])]).objects[0]\n",
    "            evidence_doc_number = evidence_doc.properties['doc_id']\n",
    "            evidence_doc_name = evidence_doc.references['parent'].objects[0].properties['doc_name']\n",
    "            sp_fact.append([evidence_doc_name, int(evidence_doc_number)])\n",
    "        except:\n",
    "            print(f\"can't find this document {doc_id}.\")\n",
    "    df.loc[i, 'support_fact'] = str(sp_fact)\n",
    "    if (i+1) % 10 == 0:\n",
    "        df.to_json(\"hotpot_df.json\", orient=\"records\", lines=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_id</th>\n",
       "      <th>answer</th>\n",
       "      <th>support_fact</th>\n",
       "      <th>org_res_from_long_mem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5a8b57f25542995d1e6f1371</td>\n",
       "      <td>Yes</td>\n",
       "      <td>[['Scott Derrickson', 0], ['Ed Wood', 0]]</td>\n",
       "      <td>{'search times': 2, 'used queries': ['Were Sco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5a8c7595554299585d9e36b6</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'search times': 4, 'used queries': ['What gov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5a85ea095542994775f606a8</td>\n",
       "      <td>Animorphs</td>\n",
       "      <td>[['Animorphs', 0], ['Animorphs', 1]]</td>\n",
       "      <td>{'search times': 1, 'used queries': ['What sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5adbf0a255429947ff17385a</td>\n",
       "      <td>None</td>\n",
       "      <td>[['Laleli Mosque', 0]]</td>\n",
       "      <td>{'search times': 2, 'used queries': ['Are the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5a8e3ea95542995a26add48d</td>\n",
       "      <td>None</td>\n",
       "      <td>[['Big Stone Gap (film)', 0]]</td>\n",
       "      <td>{'search times': 1, 'used queries': ['The dire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5abd94525542992ac4f382d2</td>\n",
       "      <td>None</td>\n",
       "      <td>[['2014 S/S', 0]]</td>\n",
       "      <td>{'search times': 1, 'used queries': ['2014 S/S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5a85b2d95542997b5ce40028</td>\n",
       "      <td>Eenasul Fateh</td>\n",
       "      <td>[['Eenasul Fateh', 0]]</td>\n",
       "      <td>{'search times': 1, 'used queries': ['Who was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5a87ab905542996e4f3088c1</td>\n",
       "      <td>3677</td>\n",
       "      <td>[['Androscoggin Bank Colisée', 0]]</td>\n",
       "      <td>{'search times': 1, 'used queries': ['The aren...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5a7bbb64554299042af8f7cc</td>\n",
       "      <td>Terry Richardson</td>\n",
       "      <td>[['Terry Richardson', 0], ['Annie Morton', 0]]</td>\n",
       "      <td>{'search times': 2, 'used queries': ['Who is o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5a8db19d5542994ba4e3dd00</td>\n",
       "      <td>Yes</td>\n",
       "      <td>[['For Against', 0]]</td>\n",
       "      <td>{'search times': 2, 'used queries': ['Are Loca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                question_id            answer  \\\n",
       "0  5a8b57f25542995d1e6f1371               Yes   \n",
       "1  5a8c7595554299585d9e36b6              None   \n",
       "2  5a85ea095542994775f606a8         Animorphs   \n",
       "3  5adbf0a255429947ff17385a              None   \n",
       "4  5a8e3ea95542995a26add48d              None   \n",
       "5  5abd94525542992ac4f382d2              None   \n",
       "6  5a85b2d95542997b5ce40028     Eenasul Fateh   \n",
       "7  5a87ab905542996e4f3088c1              3677   \n",
       "8  5a7bbb64554299042af8f7cc  Terry Richardson   \n",
       "9  5a8db19d5542994ba4e3dd00               Yes   \n",
       "\n",
       "                                     support_fact  \\\n",
       "0       [['Scott Derrickson', 0], ['Ed Wood', 0]]   \n",
       "1                                              []   \n",
       "2            [['Animorphs', 0], ['Animorphs', 1]]   \n",
       "3                          [['Laleli Mosque', 0]]   \n",
       "4                   [['Big Stone Gap (film)', 0]]   \n",
       "5                               [['2014 S/S', 0]]   \n",
       "6                          [['Eenasul Fateh', 0]]   \n",
       "7              [['Androscoggin Bank Colisée', 0]]   \n",
       "8  [['Terry Richardson', 0], ['Annie Morton', 0]]   \n",
       "9                            [['For Against', 0]]   \n",
       "\n",
       "                               org_res_from_long_mem  \n",
       "0  {'search times': 2, 'used queries': ['Were Sco...  \n",
       "1  {'search times': 4, 'used queries': ['What gov...  \n",
       "2  {'search times': 1, 'used queries': ['What sci...  \n",
       "3  {'search times': 2, 'used queries': ['Are the ...  \n",
       "4  {'search times': 1, 'used queries': ['The dire...  \n",
       "5  {'search times': 1, 'used queries': ['2014 S/S...  \n",
       "6  {'search times': 1, 'used queries': ['Who was ...  \n",
       "7  {'search times': 1, 'used queries': ['The aren...  \n",
       "8  {'search times': 2, 'used queries': ['Who is o...  \n",
       "9  {'search times': 2, 'used queries': ['Are Loca...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'search times': 1,\n",
       " 'used queries': ['2014 S/S is the debut album of a South Korean boy group that was formed by who?'],\n",
       " 'searched memory': [{'doc_name': '2014 S/S',\n",
       "   'text': 'WINNER\\'s debut album, \"2014 S/S,\" was released on August 12, 2014, by YG Entertainment. The group members contributed to the lyrics and composition of most songs on the album.'}],\n",
       " 'thought': \"WINNER is the South Korean boy group formed by YG Entertainment, and their debut album '2014 S/S' was released on August 12, 2014.\",\n",
       " 'evidence': [{'text': '2014 S/S is the debut album of South Korean group WINNER.',\n",
       "   'doc_id': '5d322fc9-52e5-4e16-a951-ff8810657196',\n",
       "   'doc_name': '2014 S/S'},\n",
       "  {'text': \"It was released on August 12, 2014 by the group's record label, YG Entertainment.\",\n",
       "   'doc_id': 'c9de059e-2cf5-4e32-ac6b-c2d999a518c9',\n",
       "   'doc_name': '2014 S/S'},\n",
       "  {'text': \"The members were credited for writing the lyrics and composing the majority of the album's songs.\",\n",
       "   'doc_id': 'ada1f252-522f-462b-8284-05a8b7d3c65f',\n",
       "   'doc_name': '2014 S/S'}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 5\n",
    "res = eval(df['org_res_from_long_mem'][index])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_create(answer_prompt.format(question='2014 S/S is the debut album of a South Korean boy group that was formed by who?', docs=res['evidence']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
