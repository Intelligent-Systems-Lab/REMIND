{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate datasets from Conversation Chronicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "\n",
    "def transform_time_intervals(intervals):\n",
    "    def parse_relative_time(text):\n",
    "        match = re.match(r\"A (few|couple of) (hours|days|weeks|months|years) after\", text)\n",
    "        if match:\n",
    "            qty = 3 if match.group(1) == \"few\" else 2\n",
    "            unit = match.group(2)\n",
    "            delta = {\n",
    "                \"hours\": timedelta(hours=qty),\n",
    "                \"days\": timedelta(days=qty),\n",
    "                \"weeks\": timedelta(weeks=qty),\n",
    "                \"months\": timedelta(days=qty * 30),  # Approximate month as 30 days\n",
    "                \"years\": timedelta(days=qty * 365)  # Approximate year as 365 days\n",
    "            }\n",
    "            return delta[unit]\n",
    "        return None\n",
    "\n",
    "    def generate_timeline(events):\n",
    "        now = datetime.now() - timedelta(minutes=10)  # 固定當前時間\n",
    "        timeline = [now]\n",
    "        for event in reversed(events[1:]):\n",
    "            delta = parse_relative_time(event)\n",
    "            if delta:\n",
    "                now -= delta\n",
    "            timeline.append(now)\n",
    "\n",
    "        return list(reversed(timeline))\n",
    "    \n",
    "    result = generate_timeline(intervals)\n",
    "    if len([dt.strftime(\"%Y-%m-%d %H:%M\") for dt in result]) > 5:\n",
    "        print(f'error:{intervals}')\n",
    "    return [dt.strftime(\"%Y-%m-%d %H:%M\") for dt in result]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json('test.jsonl', lines=True)\n",
    "df = df[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A couple of years after: 381\n",
      "A few months after: 412\n",
      "A few weeks after: 408\n",
      "A few days after: 381\n",
      "A few hours after: 395\n"
     ]
    }
   ],
   "source": [
    "target_strings = ['A couple of years after', 'A few months after', 'A few weeks after' , 'A few days after', 'A few hours after']\n",
    "\n",
    "counts = {target: df['time_interval'].apply(lambda x: x.count(target)).sum() for target in target_strings}\n",
    "\n",
    "for target, count in counts.items():\n",
    "    print(f\"{target}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('test.jsonl', lines=True) # test.jsonl is Conversation Chronicles datasets\n",
    "question_df = df.copy()\n",
    "question_df = question_df.drop(['summary'], axis=1)\n",
    "question_df['time_changed'] = question_df['time_interval'].apply(transform_time_intervals)\n",
    "question_df['generate_dialogue']=None\n",
    "question_df['question_type'] = None\n",
    "question_df['question']=None\n",
    "question_df['answer']=None\n",
    "question_df['explain']=None\n",
    "question_df['evidence']=None\n",
    "question_df = question_df[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_df.to_json(\"questions_0205.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 500 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "question_df = pd.read_json('questions_0205.json', lines=True)\n",
    "question_df['time_changed'] = question_df['time_interval'].apply(transform_time_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "def llm_create(prompt):\n",
    "        messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"o3-mini\",\n",
    "            messages=messages,\n",
    "        )\n",
    "        return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog_dict = {\n",
    "    \"0\":\"first_session_dialogue\",\n",
    "    \"1\":\"second_session_dialogue\",\n",
    "    \"2\":\"third_session_dialogue\",\n",
    "    \"3\":\"fourth_session_dialogue\",\n",
    "    \"4\":\"fifth_session_dialogue\"\n",
    "}\n",
    "\n",
    "speakers_dict = {\n",
    "    \"0\":\"first_session_speakers\",\n",
    "    \"1\":\"second_session_speakers\",\n",
    "    \"2\":\"third_session_speakers\",\n",
    "    \"3\":\"fourth_session_speakers\",\n",
    "    \"4\":\"fifth_session_speakers\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_groups = [1, 5, 6, 7, 8, 9, 11, 14, 15, 16, 24, 26, 27, 30, 31, 32, 39, 41, 43, 45, 46, 49, 50, 53, 54, 57, 58, 72, 73, 79, 83, 93, 97, 99, 101, 103, 109, 110, 112, 113, 118, 119, 123, 125, 126, 127, 133, 137, 138, 140, 142, 143, 144, 145, 150, 151, 157, 165, 166, 171, 174, 177, 178, 179, 182, 192, 197, 199, 204, 205, 207, 213, 216, 217, 218, 219, 221, 225, 232, 234, 241, 243, 249, 254, 255, 258, 260, 261, 269, 270, 272, 280, 284, 288, 299, 300, 307, 310, 313, 314, 317, 321, 325, 326, 327, 328, 331, 339, 344, 345, 346, 347, 349, 350, 357, 362, 365, 367, 370, 379, 380, 381, 382, 383, 384, 388, 392, 393, 394, 395, 400, 401, 402, 408, 413, 416, 418, 419, 421, 425, 427, 428, 429, 435, 441, 442, 443, 445, 446, 448, 449, 450, 451, 453, 458, 461, 463, 467, 476, 481, 482, 485, 492, 495, 498]\n",
    "short_groups = [3, 12, 13, 17, 18, 19, 21, 22, 23, 28, 35, 36, 37, 38, 51, 52, 56, 63, 64, 66, 69, 70, 71, 75, 76, 77, 78, 80, 85, 86, 89, 90, 91, 95, 96, 98, 100, 104, 106, 107, 114, 115, 120, 124, 129, 130, 134, 139, 147, 148, 149, 152, 156, 158, 159, 164, 167, 168, 173, 175, 186, 188, 191, 195, 200, 202, 203, 206, 208, 210, 214, 215, 220, 223, 224, 228, 229, 231, 233, 235, 237, 240, 247, 251, 253, 256, 259, 263, 266, 268, 277, 278, 281, 282, 285, 289, 290, 292, 293, 297, 301, 302, 304, 308, 309, 311, 312, 319, 320, 322, 324, 333, 334, 335, 336, 351, 352, 354, 355, 356, 358, 359, 363, 364, 366, 369, 372, 375, 386, 387, 390, 396, 397, 404, 405, 406, 410, 411, 414, 417, 420, 422, 423, 426, 432, 436, 438, 444, 447, 454, 455, 456, 462, 470, 471, 473, 474, 475, 477, 480, 483, 484, 488, 489, 490, 491, 493, 494, 499]\n",
    "long_groups = [0, 2, 4, 10, 20, 25, 29, 33, 34, 40, 42, 44, 47, 48, 55, 59, 60, 61, 62, 65, 67, 68, 74, 81, 82, 84, 87, 88, 92, 94, 102, 105, 108, 111, 116, 117, 121, 122, 128, 131, 132, 135, 136, 141, 146, 153, 154, 155, 160, 161, 162, 163, 169, 170, 172, 176, 180, 181, 183, 184, 185, 187, 189, 190, 193, 194, 196, 198, 201, 209, 211, 212, 222, 226, 227, 230, 236, 238, 239, 242, 244, 245, 246, 248, 250, 252, 257, 262, 264, 265, 267, 271, 273, 274, 275, 276, 279, 283, 286, 287, 291, 294, 295, 296, 298, 303, 305, 306, 315, 316, 318, 323, 329, 330, 332, 337, 338, 340, 341, 342, 343, 348, 353, 360, 361, 368, 371, 373, 374, 376, 377, 378, 385, 389, 391, 398, 399, 403, 407, 409, 412, 415, 424, 430, 431, 433, 434, 437, 439, 440, 452, 457, 459, 460, 464, 465, 466, 468, 469, 472, 478, 479, 486, 487, 496, 497]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(165, 169, 166)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mix_groups), len(short_groups), len(long_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mix memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_memory_question_prompt = \"\"\"You are a strict question designer, and the questions you design are appropriate and uncontroversial.\n",
    "I want to generate a memory reasoning question like this:\n",
    "\n",
    "Memory 1\n",
    "User: I like drinking coffee, especially lattes.\n",
    "Assistant: Lattes are great! How do you usually drink them?\n",
    "\n",
    "Memory 2\n",
    "User: I'm allergic to milk, so I usually drink oat milk or soy milk.\n",
    "Assistant: Oat milk and soy milk are great alternatives!\n",
    "\n",
    "Example Question\n",
    "User: Do you know what I usually add to my coffee?\n",
    "\n",
    "Explanation\n",
    "This question requires combining Memory 1 (the user likes lattes) and Memory 2 (the user is allergic to milk and chooses oat milk or soy milk) to correctly answer: \"You usually add oat milk or soy milk to your coffee to make a latte.\" If only one of these memories is known, the question cannot be fully answered.\n",
    "\n",
    "WARNING:The question must require multiple dialogue memories to determine the answer. \n",
    "It should refer to a specific fact with a clear correct answer, not be too vague, because the memories are not limited to these, there are other memories as well. And the answer must be derived solely from the given memories.\n",
    "This question is asked by the first person in the conversation to the second person.\n",
    "\n",
    "Next, I will provide five different time memory entries, if any two memories can be combined to form a question, That's exactly what I need.\n",
    "It is possible that they refer to the same event, so questions involving counting occurrences may be inaccurate.\n",
    "Time is not needed in the question, if you need to use time, use relative time, avoid using absolute time.\n",
    "Current time:{current_time}\n",
    "\n",
    "Memory 1\n",
    "{memory_1}\n",
    "\n",
    "Memory 2\n",
    "{memory_2}\n",
    "\n",
    "Memory 3\n",
    "{memory_3}\n",
    "\n",
    "Memory 4\n",
    "{memory_4}\n",
    "\n",
    "Memory 5\n",
    "{memory_5}\n",
    "\n",
    "Output as json format, if the memory is not appropriate, don' answer the question, just return \"appropriate\":False\n",
    "```json\n",
    "{{\n",
    "  \"appropriate\":\"True/False\",\n",
    "  \"question\":\"asked by the first person in the conversation to the second person, no need add the person at begin\",\n",
    "  \"answer\":\"The concise answer by the second person in the conversation to the first person, no need add the person at begin\",\n",
    "  \"memory\":\"List of memory number used to generate the question, like [1,2]\",\n",
    "  \"explain\":\"A concise description of which memories need to be combined to answer the question\",\n",
    "  \"evidence\":\"List of the origin dialogue used to answer the question like ['User: I like drinking coffee, especially lattes.']\"\n",
    "}}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "not_appropriate = []\n",
    "for number, row in enumerate(mix_groups):\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            print(f'==={number}===')\n",
    "            dialog_1 = []\n",
    "            for i in range(len(question_df['first_session_dialogue'][row])):\n",
    "                dialog_1.append(f\"{question_df['first_session_speakers'][row][i]}:{question_df['first_session_dialogue'][row][i]}\")\n",
    "            dialog_1.append(question_df['time_changed'][row][0])\n",
    "            dialog_2 = []\n",
    "            for i in range(len(question_df['second_session_dialogue'][row])):\n",
    "                dialog_2.append(f\"{question_df['second_session_speakers'][row][i]}:{question_df['second_session_dialogue'][row][i]}\")\n",
    "            dialog_2.append(question_df['time_changed'][row][1])\n",
    "            dialog_3 = []\n",
    "            for i in range(len(question_df['third_session_dialogue'][row])):\n",
    "                dialog_3.append(f\"{question_df['third_session_speakers'][row][i]}:{question_df['third_session_dialogue'][row][i]}\")\n",
    "            dialog_3.append(question_df['time_changed'][row][2])\n",
    "            dialog_4 = []\n",
    "            for i in range(len(question_df['fourth_session_dialogue'][row])):\n",
    "                dialog_4.append(f\"{question_df['fourth_session_speakers'][row][i]}:{question_df['fourth_session_dialogue'][row][i]}\")\n",
    "            dialog_4.append(question_df['time_changed'][row][3])\n",
    "            dialog_5 = []\n",
    "            for i in range(len(question_df['fifth_session_dialogue'][row])):\n",
    "                dialog_5.append(f\"{question_df['fifth_session_speakers'][row][i]}:{question_df['fifth_session_dialogue'][row][i]}\")\n",
    "            dialog_5.append(question_df['time_changed'][row][4])\n",
    "            \n",
    "            current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "            res = llm_create(mix_memory_question_prompt.format(memory_1=dialog_1, memory_2=dialog_2, memory_3=dialog_3, memory_4=dialog_4, memory_5=dialog_5, current_time=current_time))\n",
    "            res_dict = json.loads(re.search(r\"```json(.*?)```\", res, re.DOTALL).group(1).strip())\n",
    "            if res_dict['appropriate']==\"True\":\n",
    "                question_df.loc[row, 'generate_dialogue'] = str(res_dict['memory'])\n",
    "                question_df.loc[row, 'question_type'] = 'mix'\n",
    "                question_df.loc[row, 'question'] = res_dict['question']\n",
    "                question_df.loc[row, 'answer'] = res_dict['answer']\n",
    "                question_df.loc[row, 'explain'] = res_dict['explain']\n",
    "                question_df.loc[row, 'evidence'] = str(res_dict['evidence'])\n",
    "            else:\n",
    "                print(f'not appropriate')\n",
    "                not_appropriate.append(row)\n",
    "            success = True\n",
    "        except Exception as e:\n",
    "            print(f'error:{e}')\n",
    "question_df.to_json(\"questions_0205.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "short memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_memory_question_prompt = \"\"\"You are a strict question designer, and the questions you design are appropriate and uncontroversial.\n",
    "I want to generate a memory question like this:\n",
    "\n",
    "Memory\n",
    "Classmates A: Are you into surfing? I'm super into surfing myself\n",
    "Classmates B: Actually I'm looking to learn. Maybe you could give me a basic lesson some time!\n",
    "Classmates A: Yeah for sure! We could go to Pacifica, the waves there are pretty light and easy\n",
    "Classmates B: That sounds awesome\n",
    "Classmates A: There's even a cool Taco Bell right by the beach, could grab a bite after\n",
    "Classmates B: What about this Sunday around noon?\n",
    "Classmates A: Yeah let's do it!\n",
    "\n",
    "Example Question\n",
    "\"Classmates A\":\"Remember that one time we went surfing about month age? What was that one place we went to for lunch called?\",\n",
    "\"Classmates B\":\"Taco Bell\"\n",
    "\n",
    "It should refer to a specific fact with a clear correct answer, not be too vague, because the memories are not limited to these, there are other memories as well. And the answer must be derived solely from the given memories.\n",
    "This question is asked by the first person in the conversation to the second person.\n",
    "Time is not needed in the question, if you need to use time, use relative time, avoid using absolute time.\n",
    "Current time:{current_time}\n",
    "\n",
    "Memory\n",
    "{memory}\n",
    "\n",
    "Output as json format\n",
    "```json\n",
    "{{\n",
    "  \"question\":\"asked by the first person in the conversation to the second person, no need add the person at begin\",\n",
    "  \"answer\":\"The concise answer by the second person in the conversation to the first person, no need add the person at begin\",\n",
    "  \"evidence\":\"List of the origin dialogue used to answer the question like ['User: I like drinking coffee, especially lattes.']\"\n",
    "}}\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import json\n",
    "\n",
    "for number, row in enumerate(short_groups):\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            print(f'==={number}===')\n",
    "            dialog = []\n",
    "            \n",
    "            time_list = question_df['time_changed'][row]\n",
    "            current_time = datetime.now()\n",
    "            one_day_ago = current_time - timedelta(days=1)\n",
    "            indices = [i for i, date_str in enumerate(time_list) if one_day_ago <= datetime.strptime(date_str, '%Y-%m-%d %H:%M')]\n",
    "            session = random.choice(indices)\n",
    "            \n",
    "            for i in range(len(question_df[dialog_dict[str(session)]][row])):\n",
    "                dialog.append(f\"{question_df[speakers_dict[str(session)]][row][i]}:{question_df[dialog_dict[str(session)]][row][i]}\")\n",
    "            dialog.append(question_df['time_changed'][row][session])\n",
    "            \n",
    "            res = llm_create(one_memory_question_prompt.format(memory=dialog, current_time=current_time.strftime(\"%Y-%m-%d %H:%M\")))\n",
    "            res_dict = json.loads(re.search(r\"```json(.*?)```\", res, re.DOTALL).group(1).strip())\n",
    "            question_df.loc[row, 'generate_dialogue'] = str([session+1])\n",
    "            question_df.loc[row, 'question_type'] = 'short'\n",
    "            question_df.loc[row, 'question'] = res_dict['question']\n",
    "            question_df.loc[row, 'answer'] = res_dict['answer']\n",
    "            question_df.loc[row, 'evidence'] = str(res_dict['evidence'])\n",
    "            success = True\n",
    "        except Exception as e:\n",
    "            print(f'error:{e}')\n",
    "question_df.to_json(\"questions_0205.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "long memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===0===\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import json\n",
    "\n",
    "for number, row in enumerate(long_groups):\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            print(f'==={number}===')\n",
    "            dialog = []\n",
    "            \n",
    "            time_list = question_df['time_changed'][row]\n",
    "            current_time = datetime.now()\n",
    "            month_ago = current_time - timedelta(days=30)\n",
    "            indices = [i for i, date_str in enumerate(time_list) if month_ago >= datetime.strptime(date_str, '%Y-%m-%d %H:%M')]\n",
    "            if indices:\n",
    "                session = random.choice(indices)\n",
    "            else:\n",
    "                print(f'Earliest time:{time_list[0]}')\n",
    "                session = 0\n",
    "            for i in range(len(question_df[dialog_dict[str(session)]][row])):\n",
    "                dialog.append(f\"{question_df[speakers_dict[str(session)]][row][i]}:{question_df[dialog_dict[str(session)]][row][i]}\")\n",
    "            dialog.append(question_df['time_changed'][row][session])\n",
    "            \n",
    "            res = llm_create(one_memory_question_prompt.format(memory=dialog, current_time=current_time.strftime(\"%Y-%m-%d %H:%M\")))\n",
    "            res_dict = json.loads(re.search(r\"```json(.*?)```\", res, re.DOTALL).group(1).strip())\n",
    "            question_df.loc[row, 'generate_dialogue'] = str([session+1])\n",
    "            question_df.loc[row, 'question_type'] = 'long'\n",
    "            question_df.loc[row, 'question'] = res_dict['question']\n",
    "            question_df.loc[row, 'answer'] = res_dict['answer']\n",
    "            question_df.loc[row, 'evidence'] = str(res_dict['evidence'])\n",
    "            success = True\n",
    "        except Exception as e:\n",
    "            print(f'error:{e}')\n",
    "question_df.to_json(\"questions_0205.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_df.to_json(\"questions_0205.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double check question sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question_df['check'] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mix type check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_mix_prompt = \"\"\"You are a strict question designer, and the questions you design are appropriate and uncontroversial.\n",
    "I will give you two memory entries and a memory reasoning question. You must determine whether the question can only be answered by combining these two memories. \n",
    "If a single memory is not enough to answer it and the answer is not too vague, respond with True; otherwise, respond with False. No explanation is needed.\n",
    "Current time:{current_time}\n",
    "\n",
    "Memory 1\n",
    "{memory_1}\n",
    "\n",
    "Memory 2\n",
    "{memory_2}\n",
    "\n",
    "Question and Answer\n",
    "{question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===0===\n"
     ]
    }
   ],
   "source": [
    "for number, row in enumerate(mix_groups):\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            print(f'==={number}===')\n",
    "            session = eval(question_df.loc[row, 'generate_dialogue'])\n",
    "            memory_1 = session[0]\n",
    "            memory_2 = session[0]\n",
    "            \n",
    "            dialog_1 = []\n",
    "            for i in range(len(question_df[dialog_dict[str(memory_1-1)]][row])):\n",
    "                dialog_1.append(f\"{question_df[speakers_dict[str(memory_1-1)]][row][i]}:{question_df[dialog_dict[str(memory_1-1)]][row][i]}\")\n",
    "            dialog_1.append(question_df['time_changed'][row][memory_1-1])\n",
    "            dialog_2 = []\n",
    "            for i in range(len(question_df[dialog_dict[str(memory_2-1)]][row])):\n",
    "                dialog_2.append(f\"{question_df[speakers_dict[str(memory_2-1)]][row][i]}:{question_df[dialog_dict[str(memory_2-1)]][row][i]}\")\n",
    "            dialog_2.append(question_df['time_changed'][row][memory_2-1])\n",
    "            \n",
    "            question = f\"{question_df[speakers_dict[str(memory_1-1)]][row][0]}:{question_df.loc[row, 'question']}, {question_df[speakers_dict[str(memory_1-1)]][row][1]}:{question_df.loc[row, 'answer']}\"\n",
    "            \n",
    "            current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "            res = llm_create(check_mix_prompt.format(memory_1=dialog_1, memory_2=dialog_2, current_time=current_time, question=question))\n",
    "            \n",
    "            question_df.loc[row, 'check'] = res\n",
    "            if res==\"False\":\n",
    "                print(f'Not appropriate:{row}')\n",
    "            success = True\n",
    "        except Exception as e:\n",
    "            print(f'error:{e}')\n",
    "question_df.to_json(\"questions_0205.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "short check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_question_prompt = \"\"\"You are a strict question designer, and the questions you design are appropriate and uncontroversial.\n",
    "I will give you a memory and a memory question. You must determine whether the question can only be answered by the memory. \n",
    "If answer is not too vague and good question, respond with True; otherwise, respond with False. No explanation is needed.\n",
    "Current time:{current_time}\n",
    "\n",
    "Memory\n",
    "{memory}\n",
    "\n",
    "Question and Answer\n",
    "{question}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===0===\n",
      "===1===\n",
      "===2===\n",
      "===3===\n",
      "===4===\n",
      "===5===\n",
      "===6===\n",
      "===7===\n",
      "===8===\n",
      "===9===\n",
      "===10===\n",
      "===11===\n",
      "===12===\n",
      "===13===\n",
      "===14===\n",
      "===15===\n",
      "===16===\n",
      "===17===\n",
      "===18===\n",
      "===19===\n",
      "===20===\n",
      "===21===\n",
      "===22===\n",
      "===23===\n",
      "===24===\n",
      "===25===\n",
      "===26===\n",
      "===27===\n",
      "===28===\n",
      "===29===\n",
      "===30===\n",
      "===31===\n",
      "===32===\n",
      "===33===\n",
      "===34===\n",
      "===35===\n",
      "===36===\n",
      "===37===\n",
      "===38===\n",
      "===39===\n",
      "===40===\n",
      "===41===\n",
      "===42===\n",
      "===43===\n",
      "===44===\n",
      "===45===\n",
      "===46===\n",
      "===47===\n",
      "===48===\n",
      "===49===\n",
      "===50===\n",
      "===51===\n",
      "===52===\n",
      "===53===\n",
      "===54===\n",
      "===55===\n",
      "===56===\n",
      "===57===\n",
      "===58===\n",
      "===59===\n",
      "===60===\n",
      "===61===\n",
      "===62===\n",
      "===63===\n",
      "===64===\n",
      "===65===\n",
      "===66===\n",
      "===67===\n",
      "===68===\n",
      "===69===\n",
      "===70===\n",
      "===71===\n",
      "===72===\n",
      "===73===\n",
      "===74===\n",
      "===75===\n",
      "===76===\n",
      "===77===\n",
      "===78===\n",
      "===79===\n",
      "===80===\n",
      "===81===\n",
      "===82===\n",
      "===83===\n",
      "===84===\n",
      "===85===\n",
      "===86===\n",
      "===87===\n",
      "===88===\n",
      "===89===\n",
      "===90===\n",
      "===91===\n",
      "===92===\n",
      "===93===\n",
      "===94===\n",
      "===95===\n",
      "===96===\n",
      "===97===\n",
      "===98===\n",
      "===99===\n",
      "===100===\n",
      "===101===\n",
      "===102===\n",
      "===103===\n",
      "===104===\n",
      "===105===\n",
      "===106===\n",
      "===107===\n",
      "===108===\n",
      "===109===\n",
      "===110===\n",
      "===111===\n",
      "===112===\n",
      "===113===\n",
      "===114===\n",
      "===115===\n",
      "===116===\n",
      "===117===\n",
      "===118===\n",
      "===119===\n",
      "===120===\n",
      "===121===\n",
      "===122===\n",
      "===123===\n",
      "===124===\n",
      "===125===\n",
      "===126===\n",
      "===127===\n",
      "===128===\n",
      "===129===\n",
      "===130===\n",
      "===131===\n",
      "===132===\n",
      "===133===\n",
      "===134===\n",
      "===135===\n",
      "===136===\n",
      "===137===\n",
      "===138===\n",
      "===139===\n",
      "===140===\n",
      "===141===\n",
      "===142===\n",
      "===143===\n",
      "===144===\n",
      "===145===\n",
      "===146===\n",
      "===147===\n",
      "===148===\n",
      "===149===\n",
      "===150===\n",
      "===151===\n",
      "===152===\n",
      "===153===\n",
      "===154===\n",
      "===155===\n",
      "===156===\n",
      "===157===\n",
      "===158===\n",
      "===159===\n",
      "===160===\n",
      "===161===\n",
      "===162===\n",
      "===163===\n",
      "===164===\n",
      "===165===\n",
      "===166===\n",
      "===167===\n",
      "===168===\n"
     ]
    }
   ],
   "source": [
    "for number, row in enumerate(short_groups):\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            print(f'==={number}===')\n",
    "            session = eval(question_df.loc[row, 'generate_dialogue'])\n",
    "            memory = session[0]\n",
    "            \n",
    "            dialog = []\n",
    "            for i in range(len(question_df[dialog_dict[str(memory-1)]][row])):\n",
    "                dialog.append(f\"{question_df[speakers_dict[str(memory-1)]][row][i]}:{question_df[dialog_dict[str(memory-1)]][row][i]}\")\n",
    "            dialog.append(question_df['time_changed'][row][memory-1])\n",
    "\n",
    "            question = f\"{question_df[speakers_dict[str(memory-1)]][row][0]}:{question_df.loc[row, 'question']}, {question_df[speakers_dict[str(memory-1)]][row][1]}:{question_df.loc[row, 'answer']}\"\n",
    "            \n",
    "            current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "            res = llm_create(check_question_prompt.format(memory=dialog, current_time=current_time, question=question))\n",
    "            \n",
    "            question_df.loc[row, 'check'] = res\n",
    "            if res==\"False\":\n",
    "                print(f'Not appropriate:{row}')\n",
    "            success = True\n",
    "        except Exception as e:\n",
    "            print(f'error:{e}')\n",
    "question_df.to_json(\"questions_0205.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "long check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for number, row in enumerate(long_groups):\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            print(f'==={number}===')\n",
    "            session = eval(question_df.loc[row, 'generate_dialogue'])\n",
    "            memory = session[0]\n",
    "            \n",
    "            dialog = []\n",
    "            for i in range(len(question_df[dialog_dict[str(memory-1)]][row])):\n",
    "                dialog.append(f\"{question_df[speakers_dict[str(memory-1)]][row][i]}:{question_df[dialog_dict[str(memory-1)]][row][i]}\")\n",
    "            dialog.append(question_df['time_changed'][row][memory-1])\n",
    "\n",
    "            question = f\"{question_df[speakers_dict[str(memory-1)]][row][0]}:{question_df.loc[row, 'question']}, {question_df[speakers_dict[str(memory-1)]][row][1]}:{question_df.loc[row, 'answer']}\"\n",
    "            \n",
    "            current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
    "            res = llm_create(check_question_prompt.format(memory=dialog, current_time=current_time, question=question))\n",
    "            \n",
    "            question_df.loc[row, 'check'] = res\n",
    "            if res==\"False\":\n",
    "                print(f'Not appropriate:{row}')\n",
    "            success = True\n",
    "        except Exception as e:\n",
    "            print(f'error:{e}')\n",
    "question_df.to_json(\"questions_0205.json\", orient=\"records\", lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
